{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwar28/data-science-books/blob/main/Cuaderno_5_Cuaderno_de_Procesamiento_digital_de_im%C3%A1genes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1L5JVBpWZA7j"
      },
      "outputs": [],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQesl5Jut0mi"
      },
      "source": [
        "# <font color=\"red\">Cuaderno 6. Introducción al Procesamiento Digital de Imágenes con Python\n",
        "\n",
        "El procesamiento de imágenes es una disciplina dentro del campo de la IT que se encarga de la manipulación, análisis y transformación de imágenes digitales. En el contexto de la visión por computadora y el aprendizaje automático, se emplean diversas técnicas para convertir imágenes en representaciones que pueden ser entendidas y procesadas por algoritmos.\n",
        "\n",
        "## <font color=\"blue\"> 6.1.1 Definición de Imagen Digital\n",
        "\n",
        "Una imagen digital es una representación discreta de una imagen analógica, en la que tanto las coordenadas espaciales como la intensidad de los píxeles han sido \"muestreadas\" y \"cuantizadas\". Esto significa que, en lugar de tener una imagen continua, tenemos una matriz de números que representan la intensidad de los píxeles en cada coordenada.\n",
        "\n",
        "En la imagen se puede apreciar que cada pixel representa un punto en la imagen y este a su vez tiene un valor discreto. El archivo o variable es un arreglo de 2D, con todos los valores de los pixeles.\n",
        "\n",
        "![matrices](https://ai.stanford.edu/~syyeung/cvweb/Pictures1/imagematrix.png)\n",
        "\n",
        "Entonces, una imagen digital no es más que una matriz de números, donde cada uno de ellos se denomina píxel. Dependiendo del espacio de color usado, el significado de estos valores varía."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRyxBZLxuHAa"
      },
      "source": [
        "\n",
        "## <font color=\"blue\">6.1.1 Tipos de Imágenes\n",
        "\n",
        "* **Imagen de Intensidad (Escala de Grises):** Cada píxel en la imagen tiene un solo valor que representa la\n",
        "intensidad de la luz (generalmente en un rango de 0 a 255 para imágenes de 8 bits).\n",
        "\n",
        "* **Imagen Binaria (Blaco y Negro):** Una imagen que tiene solo dos valores posibles por píxel (0 y 1), representando blanco y negro.\n",
        "\n",
        "* **Imagen en Color:** Cada píxel se representa con tres valores de intensidad, uno para cada canal de color (RGB: Rojo, Verde y Azul)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY1p1lO_0ii0"
      },
      "source": [
        "R##<font color=\"blue\"> 6.1.2 Explicación de imágenes como arreglos 1D, 2D y 3D:\n",
        "\n",
        "Las imágenes pueden representarse de diferentes maneras en función de sus dimensiones. Cuando se trata de imágenes digitales, las representaciones más comunes son en forma de arreglos multidimensionales, es decir, matrices de números que codifican los valores de los píxeles de la imagen. Aquí vamos a explicar cómo una imagen puede ser representada como un arreglo de una, dos o tres dimensiones.\n",
        "\n",
        "![imagen](https://aprendeconalf.es/docencia/python/manual/img/arrays.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdizxHvYvAU6"
      },
      "source": [
        "## <font color=\"red\">6.2 Módulos de Python para Procesamiento de Imágenes\n",
        "\n",
        "Los módulos más utilizados para procesamiento de imágenes en Python incluyen:\n",
        "\n",
        "**OpenCV (cv2):** Para operaciones de visión por computadora de bajo nivel, como leer, escribir, modificar y analizar imágenes.\n",
        "\n",
        "**NumPy:** Para manejar y manipular arrays que representan imágenes.\n",
        "\n",
        "**Matplotlib:** Para visualizar imágenes y realizar gráficos.\n",
        "\n",
        "**Pillow (PIL):** Para operaciones de alto nivel en imágenes como transformaciones o filtrado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7UdYeqi0iis"
      },
      "source": [
        "En Python, existen varias bibliotecas potentes que facilitan el procesamiento de imágenes, como [OpenCV](http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html), [SciKit-Image] (http://scikit-image.org/) y [Pillow](http://python-pillow.org/).\n",
        "\n",
        "El objetivo de este cuaderno es comprender los fundamentos de algunas técnicas simples de procesamiento de imágenes y adentrarnos a las convoluciones o filtros para aplicarlas en las redes convolucionales,  que serán necesarias para aprender procesamiento de imagenes con Deep Learning.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vlKsiPPwoA6"
      },
      "source": [
        "##<font color=\"blue\">6.2.1 Instalación de paquetes\n",
        "\n",
        "En Anaconda, para instalar OpenCV, por ejemplo, puedes usar el siguiente comando en el terminal:\n",
        "\n",
        "\n",
        "```python\n",
        "conda install -c conda-forge opencv\n",
        "```\n",
        "\n",
        "En Google Colab, puedes instalar estos paquetes usando pip:\n",
        "\n",
        "```python\n",
        "!pip install opencv-python numpy matplotlib pillow\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC4jt7m5xgAN"
      },
      "source": [
        "## <font color=\"blue\">6.2.2 Importación de Módulos\n",
        "Una vez instalados los paquetes, puedes importarlos de la siguiente manera en tu script de Python:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTN9-G1_wonF"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv                  # open vision library OpenCV\n",
        "import numpy as np                # funciones numéricas (arrays, matrices, etc.)\n",
        "import matplotlib.pyplot as plt   # funciones para representación gráfica\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQiv4iZ4woyT"
      },
      "source": [
        "## <font color=\"blue\">6.2.3 Lectura, Visualización y Escritura de Imágenes\n",
        "**Leer una Imagen**\n",
        "Para leer una imagen con OpenCV, puedes utilizar la función cv.imread(), que carga una imagen en formato de matriz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRIzVrbKx46o"
      },
      "outputs": [],
      "source": [
        "#Descargar de https://github.com/adiacla/bigdata/blob/master/logo.jpg\n",
        "!curl -O https://raw.githubusercontent.com/adiacla/bigdata/master/logo.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RU8TKwF6wo84"
      },
      "outputs": [],
      "source": [
        "img = cv.imread('logo.jpg')\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3OXOT6zo1MY"
      },
      "outputs": [],
      "source": [
        "#Voy a ver la capa 1 del arreglo de la imagen llamado img\n",
        "img[:,:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp-LQ6omySMl"
      },
      "source": [
        "Por defecto, OpenCV lee la imagen en formato BGR (Blue, Green, Red). Si deseas trabajar con el formato RGB, puedes convertirlo usando:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5MygsrIyUko"
      },
      "outputs": [],
      "source": [
        "img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "img_rgb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a16_xktEwpKe"
      },
      "source": [
        "**Visualizar la Imagen**\n",
        "\n",
        "\n",
        "Para visualizar una imagen como pudo evidenciar, en Google Colab solo llama la variable, pero en ambientes de py es utilizando matplotlib, puedes hacerlo de la siguiente manera."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpOrYwIqwpWR"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img_rgb)\n",
        "plt.axis('off')  # Ocultar los ejes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHZFdtveythO"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img_rgb)\n",
        "plt.axis('on')  # Cn los los ejes\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGSE9ERvyyId"
      },
      "source": [
        "**Escribir una Imagen**\n",
        "\n",
        "Para guardar una imagen modificada en disco, utilizamos cv.imwrite():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzORP6n0y7J7"
      },
      "outputs": [],
      "source": [
        "cv.imwrite('output_image.jpg', img)\n",
        "#Ir a la carpeta respectiva y observa el archivo llamado output_image.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yslbWXrzIVH"
      },
      "source": [
        "**Conversión de Formatos de Imagen**\n",
        "\n",
        "Las imágenes pueden ser convertidas a escala de grises para facilitar ciertos tipos de análisis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rGG4bczzM-E"
      },
      "outputs": [],
      "source": [
        "img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "plt.imshow(img_gray, cmap='gray')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQP5DGi_zQ79"
      },
      "source": [
        "##<font color=\"red\">6.3 Tipos de Imágenes y Conversiones\n",
        "\n",
        "**Conversión entre tipos de imágenes:**\n",
        "Si necesitamos cambiar el tipo de una imagen (por ejemplo, de uint8 a float32), podemos usar el método astype() de NumPy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IWNc2__zZQM"
      },
      "outputs": [],
      "source": [
        "img_float = img_gray.astype(np.float32)  # Convertir a float32\n",
        "img_back_to_uint8 = img_float.astype(np.uint8)  # Convertir de nuevo a uint8\n",
        "img_back_to_uint8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8vCCObjzkrj"
      },
      "source": [
        "**Selección de subregiones:**\n",
        "\n",
        "Puedes seleccionar una parte de la imagen (un subconjunto de píxeles) utilizando índices de la matriz de la imagen. Por ejemplo, si deseas extraer una sección del logo de la imagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUFFfNlnzxsZ"
      },
      "outputs": [],
      "source": [
        "img_back_to_uint8[160:200, 50:170]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn0r3__M0pMd"
      },
      "source": [
        "#<font color=\"blue\">6.3.1 Escala de Grises\n",
        "\n",
        "Este código convierte una imagen a escala de grises y luego la muestra utilizando la biblioteca Matplotlib. Primero, la imagen se convierte de su formato de color original (BGR) a escala de grises. Después, la imagen resultante se visualiza con un mapa de colores en escala de grises."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SizG2ccIe7Uo"
      },
      "outputs": [],
      "source": [
        "# Convertir la imagen a escala de grise\n",
        "gray_image = cv.cvtColor(img_rgb, cv.COLOR_BGR2GRAY)\n",
        "# Mostrar la imagen usando Matplotlib\n",
        "plt.imshow(gray_image, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvocSB0M1GgI"
      },
      "source": [
        "## <font color=\"blue\">6.3.2 Redimensionamiento de una imagen a un nuevo tamaño y visualización\n",
        "\n",
        "Este código redimensiona una imagen a un tamaño específico (100x100 píxeles) utilizando OpenCV, y luego la muestra utilizando Matplotlib. Primero, se definen las dimensiones deseadas de la imagen, y luego se utiliza la función cv2.resize para cambiar el tamaño de la imagen. Finalmente, la imagen redimensionada se muestra en pantalla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztDsuxHShbcB"
      },
      "outputs": [],
      "source": [
        "# Definir el nuevo tamaño\n",
        "new_width, new_height = 100, 100  # Establecer las nuevas dimensiones deseadas (ancho y alto)\n",
        "\n",
        "# Redimensionar la imagen\n",
        "image_resized = cv.resize(img_rgb, (new_width, new_height))  # Redimensiona la imagen a las nuevas dimensiones\n",
        "\n",
        "# Mostrar la imagen redimensionada\n",
        "plt.imshow(image_resized)  # Muestra la imagen redimensionada utilizando Matplotlib\n",
        "plt.show()  # Muestra la ventana con la imagen redimensionada\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4DvKDli0iiz"
      },
      "source": [
        "## <font color=\"blue\">6.3.3 Acceso a un canal de color de una imagen cargada\n",
        "\n",
        "El código no muestra la imagen en su totalidad, sino que se centra en una porción de la imagen, específicamente los primeros 254 píxeles de las primeras 254 filas, y accede al canal azul."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swIUjSIH0iiz"
      },
      "outputs": [],
      "source": [
        "im = plt.imread('/content/logo.jpg')\n",
        "\n",
        "#im.shape\n",
        "im[:254,:254,2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwxFbaRKBlCH"
      },
      "outputs": [],
      "source": [
        "im[:254,:254,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sbrvqAG1_Jw"
      },
      "outputs": [],
      "source": [
        "im[:254,:254,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bf1HeN33aoc"
      },
      "source": [
        "**Imágenes como arreglos 1D:**\n",
        "\n",
        "En la forma más simple, una imagen podría representarse como un arreglo unidimensional (1D). Este tipo de representación es muy rara en el contexto de imágenes, pero se puede entender mejor al imaginar que se aplana la imagen en una secuencia lineal de píxeles.\n",
        "\n",
        "Ejemplo: Si tenemos una imagen muy pequeña de 3 píxeles (blanco, negro y gris), podríamos representarla como un arreglo 1D:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSHk3w-l3gh_"
      },
      "outputs": [],
      "source": [
        "[255, 0, 128] # Blanco, Negro y Gris"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfizqpvF3yy9"
      },
      "source": [
        "**Imágenes como arreglos 2D (Escala de grises):**\n",
        "\n",
        "Una imagen en escala de grises se puede representar como un arreglo bidimensional (2D), en donde cada valor de la matriz corresponde a la intensidad de un píxel en la imagen. Este tipo de representación es común cuando la imagen no tiene color, sino solo variaciones de luz.\n",
        "\n",
        "Ejemplo: Imagina una imagen de 3x3 píxeles en escala de grises:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV67x6LW37Ue"
      },
      "outputs": [],
      "source": [
        "[[255, 0, 128],     # Fila 1: Blanco, Negro, Gris\n",
        " [50, 200, 100],    # Fila 2: Gris oscuro, Rojo, Verde\n",
        " [0, 255, 50]]      # Fila 3: Negro, Blanco, Verde\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH3PrQHX4DFk"
      },
      "source": [
        "**Imágenes como arreglos 3D (RGB o color):**\n",
        "\n",
        "Las imágenes a color, como las que ves en una pantalla, se representan comúnmente como arreglos tridimensionales (3D). Aquí, cada píxel no tiene solo un valor de intensidad, sino tres valores,\n",
        "correspondientes a los colores primarios: **rojo (R), verde (G) y azul (B)**. La representación de una imagen colorida es entonces una matriz 3D, donde:\n",
        "\n",
        "La primera dimensión es el número de filas (alto de la imagen).\n",
        "\n",
        "La segunda dimensión es el número de columnas (ancho de la imagen).\n",
        "\n",
        "La tercera dimensión tiene una longitud de 3, que corresponde a los canales de color (Rojo, Verde y Azul).\n",
        "\n",
        "Ejemplo: Imagina una imagen de 2x2 píxeles a color, donde cada valor de cada píxel se expresa en términos de RGB. El arreglo 3D correspondiente sería:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAuhSg3q4RVM"
      },
      "outputs": [],
      "source": [
        "[\n",
        " [[255, 0, 0], [0, 255, 0]],    # Fila 1: Rojo, Verde\n",
        " [[0, 0, 255], [255, 255, 0]]   # Fila 2: Azul, Amarillo\n",
        "]\n",
        "\n",
        "#Visualizaremos la imagen.\n",
        "plt.imshow([ [[255, 0, 0], [0, 255, 0]],    # Fila 1: Rojo, Verde\n",
        " [[0, 0, 255], [255, 255, 0]]   # Fila 2: Azul, Amarillo\n",
        "])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IKlcV-k4kNQ"
      },
      "source": [
        "**1D:** Es una representación plana y poco común para imágenes, adecuada solo en ciertos casos de procesamiento.\n",
        "\n",
        "**2D:** Es común para imágenes en escala de grises, donde cada píxel tiene solo un valor de intensidad.\n",
        "\n",
        "**3D:** Es la forma estándar para imágenes a color (RGB), donde cada píxel tiene tres valores representando los canales de color."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY57bEv42YEG"
      },
      "source": [
        "##<font color=\"red\">6.4 Inspección de las dimensiones de un arreglo multidimensional\n",
        "\n",
        "Este código crea un arreglo NumPy tridimensional que representa una imagen con dos filas de píxeles, donde cada píxel tiene tres valores (RGB). Luego, el código muestra las dimensiones del arreglo utilizando el atributo .shape de NumPy, que devuelve la forma (tamaño) del arreglo en cada eje."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B95p_BGYyRCh"
      },
      "outputs": [],
      "source": [
        "a = np.array([[[10, 40, 70], [20,90,70],[10,30,0],[90,60,90]],\n",
        "                [[255, 0, 127], [70,40,50],[40,30,20],[50,50,80]]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qC7_ybjqVBrv"
      },
      "outputs": [],
      "source": [
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck4h728oym_x"
      },
      "outputs": [],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2pTxZPVzpjg"
      },
      "source": [
        "a.ndim : Devuelve el número de dimensiones del array a.\n",
        "\n",
        "a.shape : Devuelve una tupla con las dimensiones del array a.\n",
        "\n",
        "a.size : Devuelve el número de elementos del array a.\n",
        "\n",
        "a.dtype: Devuelve el tipo de datos de los elementos del array a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T36FD7qFzoN3"
      },
      "outputs": [],
      "source": [
        "a.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqAV3EeMzwHK"
      },
      "outputs": [],
      "source": [
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNhjDlB_zyW8"
      },
      "outputs": [],
      "source": [
        "a.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFRAT1Jez4Eh"
      },
      "outputs": [],
      "source": [
        "a.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mScuUPzZ5sWj"
      },
      "source": [
        "##<font color=\"red\"> 6.5 Concatenación de arreglos 3D en NumPy\n",
        "\n",
        "Este código crea dos arreglos tridimensionales (a y a2) y luego los concatena a lo largo del primer eje (filas). Esto permite combinar dos bloques de píxeles (representados como matrices 3D) en un único arreglo más grande. La concatenación se realiza utilizando la función np.concatenate(), especificando axis=0 para indicar que la operación debe realizarse a lo largo del primer eje, es decir, apilando los arreglos verticalmente (añadiendo filas)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr8hHbmFz6Zh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Primer arreglo 3D 'a' (con 2 filas y 4 píxeles por fila, cada uno con 3 valores RGB)\n",
        "a = np.array([[[10, 40, 70], [20, 90, 70], [10, 30, 0], [90, 60, 90]],\n",
        "              [[255, 0, 127], [70, 40, 50], [40, 30, 20], [50, 50, 80]]])\n",
        "\n",
        "# Segundo arreglo 3D 'a2' (también con 2 filas y 4 píxeles por fila, cada uno con 3 valores RGB)\n",
        "a2 = np.array([[[255, 64, 0], [255, 128, 0], [255, 191, 0], [255, 255, 0]],\n",
        "               [[42, 87, 131], [120, 169, 206], [64, 255, 0], [0, 255, 0]]])\n",
        "\n",
        "# Concatenar los dos arreglos a lo largo del eje 0 (filas)\n",
        "a = np.concatenate((a, a2), axis=0)\n",
        "\n",
        "# Mostrar la forma del arreglo concatenado (nueva imagen)\n",
        "print(a.shape)  # Devuelve las dimensiones del arreglo concatenado\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcQpEQG91NWF"
      },
      "outputs": [],
      "source": [
        "# Mostrar la imagen\n",
        "plt.imshow(a)\n",
        "plt.axis('off')  # Desactivar ejes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJXK0VSU585Z"
      },
      "source": [
        "##<font color=\"red\"> 6.6 Iteración sobre un canal específico de una imagen 3D en NumPy\n",
        "Este código itera a través de todos los valores del primer canal (rojo) de la imagen a, que se ha representado como un arreglo 3D. Utiliza np.nditer() para recorrer todos los elementos de una sección específica del arreglo (en este caso, la primera capa o canal de color, que corresponde al valor en el índice 0 de cada píxel). La iteración extrae y muestra cada valor del canal rojo de la imagen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CBflSohxPb5"
      },
      "outputs": [],
      "source": [
        "# Iterar sobre el primer canal de la imagen (el canal rojo, índice 0)\n",
        "for x in np.nditer(a[:,:,0]):\n",
        "    print(x)  # Imprime cada valor del canal rojo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzb0xuF06Ryb"
      },
      "source": [
        "##<font color=\"blue\">6.6.1 Aplanar un arreglo 3D a un arreglo 1D en NumPy\n",
        "Para convertir un arreglo multidimensional (como una imagen representada en 3D) en un arreglo unidimensional (1D), se puede utilizar el método flatten() o la función ravel() de NumPy. Estas funciones \"aplanan\" el arreglo, es decir, lo convierten en una secuencia lineal de valores.\n",
        "\n",
        "Esta operación no se visualiza el arreglo plano, pero si es necesario aprenderlo para usarlo en las redes neuronales porque la capa de entrada solo recibe arreglos planos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAe-MUoh6igf"
      },
      "outputs": [],
      "source": [
        "# Aplanar el arreglo 3D en un arreglo 1D\n",
        "flattened_array = a.flatten()  # Usa flatten() para aplanar el arreglo\n",
        "\n",
        "# Mostrar el arreglo aplanado\n",
        "print(flattened_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEAG5N3f6xc8"
      },
      "source": [
        "##<font color=\"blue\">6.6.2 Alternativa con ravel():\n",
        "\n",
        "ravel() también aplanea un arreglo, pero a diferencia de flatten(), ravel() devuelve una vista del arreglo original cuando es posible, lo que puede ser más eficiente en términos de memoria.\n",
        "En este caso, el uso de ravel() produciría el mismo resultado que flatten()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Uk-tETu61nd"
      },
      "outputs": [],
      "source": [
        "flattened_array_ravel = a.ravel()  # Alternativa con ravel()\n",
        "print(flattened_array_ravel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SpSRYYs67VJ"
      },
      "source": [
        "##<font color=\"red\">6.7 Visualización del primer canal de una imagen (rojo) usando Matplotlib\n",
        "\n",
        "Este código muestra cómo visualizar solo el primer canal (rojo) de una imagen representada en un arreglo 3D utilizando la biblioteca Matplotlib. La imagen original se encuentra en el arreglo a, y se selecciona el primer canal (a[:,:,0]) para su visualización. Además, se desactivan los ejes para una visualización más limpia de la imagen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPdePRXA6igz"
      },
      "outputs": [],
      "source": [
        "# Mostrar solo el primer canal (rojo) de la imagen\n",
        "plt.imshow(a[:,:,0])\n",
        "plt.axis('off')  # Desactivar los ejes para una visualización más limpia\n",
        "plt.show()  # Mostrar la imagen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABIMLJev3-zU"
      },
      "source": [
        "[Codigos colores](\"https://www.w3schools.com/colors/colors_picker.asp\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw6KFmeB7-i4"
      },
      "source": [
        "# <font color=\"red\">6.8 Función auxiliar para mostrar una imagen con Matplotlib en un tamaño ajustado\n",
        "\n",
        "Este código define una función auxiliar llamada plti, que permite mostrar una imagen de manera que se ajuste a un tamaño proporcional según las dimensiones de la imagen. Esta función la vamos a usar más adelante en los ejercicios.\n",
        "\n",
        "La altura de la imagen (h) se especifica como un parámetro, y la anchura se calcula de forma proporcional para mantener las proporciones de la imagen.\n",
        "\n",
        "La función usa Matplotlib para visualizar la imagen y desactivar los ejes.\n",
        "\n",
        "\n",
        "Esta función plti es un ayudante para trazar una imagen utilizando matplotlib. Aquí está cómo funciona:\n",
        "\n",
        "Toma una matriz de imagen im como entrada.\n",
        "\n",
        "h es un parámetro opcional que especifica la altura de la imagen en pulgadas. El valor predeterminado es 8 pulgadas.\n",
        "\n",
        "Calcula la relación de aspecto de la imagen dividiendo la altura (y) entre la anchura (x) y luego ajusta la anchura (w) en consecuencia para mantener la relación de aspecto original.\n",
        "Crea una figura con el tamaño ajustado según la relación de aspecto calculada y la altura especificada (h).\n",
        "Utiliza plt.imshow() para mostrar la imagen im sin interpolación y con cualquier otro argumento adicional especificado en **kwargs.\n",
        "Finalmente, desactiva los ejes de la imagen utilizando plt.axis('off').\n",
        "Esta función facilita el trazado de imágenes con matplotlib al manejar automáticamente el tamaño y la relación de aspecto de la imagen para que se muestre correctamente en la figura."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7joT4qXu0ii1",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def plti(im, h, **kwargs):\n",
        "    \"\"\"\n",
        "    Función auxiliar para mostrar una imagen con un tamaño proporcional.\n",
        "\n",
        "    Parameters:\n",
        "    im (array): La imagen a mostrar.\n",
        "    h (int or float): La altura deseada de la imagen en pulgadas.\n",
        "    kwargs: Argumentos adicionales que se pasan a la función imshow.\n",
        "    \"\"\"\n",
        "    # Obtener las dimensiones de la imagen (alto y ancho)\n",
        "    y = im.shape[0]  # Altura de la imagen\n",
        "    x = im.shape[1]  # Ancho de la imagen\n",
        "\n",
        "    # Calcular el ancho proporcional en función de la altura 'h'\n",
        "    w = (y / x) * h\n",
        "\n",
        "    # Crear la figura con el tamaño calculado\n",
        "    plt.figure(figsize=(w, h))\n",
        "\n",
        "    # Mostrar la imagen sin interpolación (para evitar distorsión)\n",
        "    plt.imshow(im, interpolation=\"none\", **kwargs)\n",
        "\n",
        "    # Desactivar los ejes para una visualización más limpia\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Mostrar la imagen\n",
        "    plt.show()\n",
        "\n",
        "# Llamar a la función plti para mostrar una imagen\n",
        "plti(im,1) #1 pulgdas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wir91ttC8J3G"
      },
      "source": [
        "# <font color=\"red\"> 6.9 Usar la libreria de opencv\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Ahora usamos la función cv2.imread() de OpenCV para cargar la imagen ubicada en la ruta definida arriba, para luego desplegarla en pantalla usando cv2.imshow().\n",
        "\n",
        "En Google Colab, es mejor usar cv2_imshow() de OpenCV en lugar de plt.imshow() para mostrar imágenes que se cargan utilizando OpenCV (cv2). Esto se debe a que cv2.imshow() no funciona correctamente en entornos como Google Colab debido a la falta de una interfaz gráfica. Sin embargo, cv2_imshow() está específicamente diseñado para mostrar imágenes en este tipo de entornos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGG12eqm8Hee"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "# Mostramos la imagen usando cv2_imshow\n",
        "cv2_imshow(img)\n",
        "\n",
        "# Opcional: esperar a que se cierre la ventana (no necesario en Colab)\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()\n",
        "# En Google Colab, es mejor usar cv2_imshow() en lugar de"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcxfaxLg0ii1"
      },
      "source": [
        "## <font color=\"red\">6.10 Recorte y visualización de una sección de una imagen en Google Colab\n",
        "\n",
        "Este código descarga una imagen de Internet, la carga en un arreglo usando plt.imread(), y luego recorta una sección específica de la imagen. Finalmente, se muestra la sección recortada de la imagen utilizando plt.imshow().\n",
        "\n",
        "Vamos a recortar esta foto de Fornite. Esta es la imagen original.\n",
        "\n",
        "![image](https://cdn2.unrealengine.com/fortnite-og-social-1920x1080-a5adda66fab9.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ap72CDx0ii2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Descargar la imagen de una URL\n",
        "!curl -O \"https://cdn2.unrealengine.com/fortnite-og-social-1920x1080-a5adda66fab9.jpg\"\n",
        "\n",
        "# Cargar la imagen usando Matplotlib\n",
        "im = plt.imread(\"/content/fortnite-og-social-1920x1080-a5adda66fab9.jpg\")\n",
        "\n",
        "# Imprimir las dimensiones de la imagen (alto, ancho, canales)\n",
        "print(im.shape)\n",
        "\n",
        "# Recortar una sección de la imagen (de las filas 300 a 800 y de las columnas 500 a 800)\n",
        "im3 = im[300:800, 500:800, :]\n",
        "\n",
        "# Mostrar la imagen recortada\n",
        "plt.imshow(im3)\n",
        "plt.axis('off')  # Desactivar los ejes para una visualización más limpia\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMojFUwYAtC9"
      },
      "source": [
        "## <font color=\"blue\">6.10.1 Extracción de un canal específico de una imagen recortada\n",
        "\n",
        "Este código recorta una sección específica de la imagen y luego extrae solo el primer canal (rojo, correspondiente al índice 0 en una imagen en formato RGB) de la sección recortada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "barjU3XI5zHu"
      },
      "outputs": [],
      "source": [
        "# Recortar una sección de la imagen (de las filas 200 a 600 y de las columnas 500 a 800)\n",
        "# Luego, extraer solo el canal rojo (el primer canal, índice 0)\n",
        "im0 = im[200:600, 500:800, 0]\n",
        "\n",
        "# Mostrar el resultado de la sección recortada con solo el canal rojo\n",
        "print(im0)\n",
        "im0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw56seq-BGHn"
      },
      "source": [
        "##<font color=\"blue\">6.10.2 Extracción y visualización de solo el canal verde de una imagen\n",
        "\n",
        "Este código extrae solo el canal verde de una sección recortada de la imagen y luego crea una nueva imagen en la que solo el canal verde tiene información de color, mientras que los canales rojo y azul se configuran a 0. Finalmente, se muestra la nueva imagen resultante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0C662bV6Rbp"
      },
      "outputs": [],
      "source": [
        "# Recortar una sección de la imagen original (de las filas 200 a 600 y de las columnas 500 a 800)\n",
        "# Crear una imagen vacía de la misma forma\n",
        "im0_color = np.zeros_like(im[200:600, 500:800])  # Crear un arreglo vacío con la misma forma\n",
        "\n",
        "# Asignar el canal rojo a 0\n",
        "im0_color[..., 0] = 0\n",
        "\n",
        "# Establecer el canal verde con los valores del canal verde de la imagen original\n",
        "im0_color[..., 1] = im[200:600, 500:800, 1]\n",
        "\n",
        "# Asignar el canal azul a 0\n",
        "im0_color[..., 2] = 0\n",
        "\n",
        "# Mostrar la imagen resultante con solo el canal verde\n",
        "plti(im0_color,4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-otBEk05BofM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnTo_1nQBgZX"
      },
      "outputs": [],
      "source": [
        "# Recortar una sección de la imagen original (de las filas 200 a 600 y de las columnas 500 a 800)\n",
        "# Crear una imagen vacía de la misma forma\n",
        "im0_color = np.zeros_like(im[200:600, 500:800])  # Crear un arreglo vacío con la misma forma\n",
        "\n",
        "#Establecer el canal rojo con los valores del canal rojo de la imagen original\n",
        "im0_color[..., 0] = im[200:600, 500:800, 0]\n",
        "\n",
        "\n",
        "# Asignar el canal verde a 0\n",
        "im0_color[..., 1] = 0\n",
        "\n",
        "# Asignar el canal azul a 0\n",
        "im0_color[..., 2] = 0\n",
        "\n",
        "# Mostrar la imagen resultante con solo el canal verde\n",
        "plti(im0_color,4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GWfp2rpB1sn"
      },
      "outputs": [],
      "source": [
        "# Recortar una sección de la imagen original (de las filas 200 a 600 y de las columnas 500 a 800)\n",
        "# Crear una imagen vacía de la misma forma\n",
        "im0_color = np.zeros_like(im[200:600, 500:800])  # Crear un arreglo vacío con la misma forma\n",
        "\n",
        "# Asignar el canal rojo a 0\n",
        "im0_color[..., 0] = 0\n",
        "\n",
        "# Asignar el canal verde a 0\n",
        "im0_color[..., 1] = 0\n",
        "\n",
        "#Establecer el canal verde con los valores del canal verde de la imagen original\n",
        "\n",
        "im0_color[..., 2] = im[200:600, 500:800, 2]\n",
        "\n",
        "# Mostrar la imagen resultante con solo el canal verde\n",
        "plti(im0_color,4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6i-ZLpUCVOT"
      },
      "source": [
        "# <font color=\"blue\">6.10.3 Visualizar cada capa o canal de color individualmente\n",
        "\n",
        "Este código extrae y muestra los canales individuales de una imagen cargada (im), que contiene tres canales de color: rojo, verde y azul. Utiliza Matplotlib para mostrar cada canal en una figura separada en escala de grises. Los tres canales se visualizan en una única fila de subgráficos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N47UpHryC_ib"
      },
      "source": [
        "La razón por la que los canales rojo, verde y azul se muestran en blanco y negro (escala de grises) es porque se están visualizando por separado en escala de grises en lugar de mostrarse como imágenes a color.\n",
        "\n",
        "**Explicación detallada:**\n",
        "\n",
        "Cada imagen en formato RGB tiene tres canales:\n",
        "\n",
        "Canal Rojo (R)\n",
        "\n",
        "Canal Verde (G)\n",
        "\n",
        "Canal Azul (B)\n",
        "\n",
        "\n",
        "Cuando haces un recorte de los canales individuales como im[:, :, 0], im[:, :, 1] y im[:, :, 2], lo que estás obteniendo son matrices 2D (de forma alto x ancho) que contienen solo los valores de intensidad de cada canal, sin ninguna mezcla de color. Estos valores son simplemente números que representan la intensidad de ese canal en cada píxel.\n",
        "\n",
        "\n",
        "Cuando usas plt.imshow(..., cmap='gray'), Matplotlib interpreta esas intensidades de canal y las muestra como imágenes en escala de grises. En este caso, cada imagen está representando una intensidad de color sin ningún color adicional, por lo que el resultado es una imagen blanco y negro donde los valores más altos corresponden a tonos más claros y los valores más bajos a tonos más oscuros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfIq-dQJ1c6r"
      },
      "outputs": [],
      "source": [
        "# Supongamos que 'im' es la imagen cargada\n",
        "red_channel = im[:, :, 0]    # Canal rojo\n",
        "green_channel = im[:, :, 1]  # Canal verde\n",
        "blue_channel = im[:, :, 2]   # Canal azul\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NUouGv1188-"
      },
      "outputs": [],
      "source": [
        "# Visualizar los canales\n",
        "plt.figure(figsize=(15, 5))  # Definir el tamaño de la figura\n",
        "\n",
        "# Canal Rojo\n",
        "plt.subplot(1, 3, 1)  # Crear el primer subgráfico (1 fila, 3 columnas, 1er subgráfico)\n",
        "plt.imshow(red_channel, cmap='gray')  # Mostrar el canal rojo en escala de grises\n",
        "plt.title('Canal Rojo')  # Título del subgráfico\n",
        "plt.axis('off')  # Desactivar los ejes para una visualización más limpia\n",
        "\n",
        "# Canal Verde\n",
        "plt.subplot(1, 3, 2)  # Crear el segundo subgráfico\n",
        "plt.imshow(green_channel, cmap='gray')  # Mostrar el canal verde en escala de grises\n",
        "plt.title('Canal Verde')  # Título del subgráfico\n",
        "plt.axis('off')  # Desactivar los ejes\n",
        "\n",
        "# Canal Azul\n",
        "plt.subplot(1, 3, 3)  # Crear el tercer subgráfico\n",
        "plt.imshow(blue_channel, cmap='gray')  # Mostrar el canal azul en escala de grises\n",
        "plt.title('Canal Azul')  # Título del subgráfico\n",
        "plt.axis('off')  # Desactivar los ejes\n",
        "\n",
        "plt.tight_layout()  # Ajustar el espacio entre los subgráficos para que no se solapen\n",
        "plt.show()  # Mostrar la figura con los tres canales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH12jQFaDVzO"
      },
      "source": [
        "## <font color=\"blue\">6.10.4 Visualización de los canales individuales de color con su respectivo color en la imagen\n",
        "\n",
        "Este código carga una imagen, extrae una sección de ella y luego crea imágenes para cada uno de los canales de color (rojo, verde y azul) de esa región. Para cada canal, se construye una nueva imagen en la que solo el canal seleccionado tiene valores, mientras que los otros dos canales están apagados (en 0). Luego, se muestran las tres imágenes con sus colores respectivos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sleKoAW82Fue"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar la imagen\n",
        "im = cv2.imread('/content/fortnite-og-social-1920x1080-a5adda66fab9.jpg')\n",
        "im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)  # Convertir de BGR a RGB\n",
        "\n",
        "# Extraer una región de la imagen (de las filas 200 a 600 y de las columnas 500 a 800)\n",
        "region = im[200:600, 500:800]\n",
        "\n",
        "# Función para crear imágenes de un solo canal\n",
        "def create_color_image(channel, color_index):\n",
        "    color_image = np.zeros_like(region)  # Crear un arreglo vacío con la misma forma\n",
        "    color_image[..., color_index] = channel  # Asignar el canal correspondiente\n",
        "    return color_image\n",
        "\n",
        "# Crear imágenes para cada canal (rojo, verde, azul)\n",
        "red_image = create_color_image(region[:, :, 0], 0)    # Imagen solo con el canal rojo\n",
        "green_image = create_color_image(region[:, :, 1], 1)  # Imagen solo con el canal verde\n",
        "blue_image = create_color_image(region[:, :, 2], 2)   # Imagen solo con el canal azul\n",
        "\n",
        "# Mostrar las imágenes en color\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Mostrar el canal rojo\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(red_image)\n",
        "plt.title('Canal Rojo')\n",
        "plt.axis('off')\n",
        "\n",
        "# Mostrar el canal verde\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(green_image)\n",
        "plt.title('Canal Verde')\n",
        "plt.axis('off')\n",
        "\n",
        "# Mostrar el canal azul\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(blue_image)\n",
        "plt.title('Canal Azul')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()  # Ajustar el espacio entre los subgráficos\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWeRqIyV0ii3"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\n",
        "\n",
        "for c, ax in zip(range(3), axs):\n",
        "    tmp_im = np.zeros(im.shape, dtype=\"uint8\")\n",
        "    tmp_im[:,:,c] = im[:,:,c]\n",
        "    ax.imshow(tmp_im)\n",
        "    ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz0fLkzQDl8o"
      },
      "source": [
        "## <font color=\"blue\">6.10.5 Visualización de canales individuales en una imagen utilizando subgráficos\n",
        "\n",
        "Este código utiliza subgráficos para mostrar los tres canales de color (rojo, verde y azul) de una imagen de forma individual. Crea una nueva imagen para cada canal, donde solo se conserva el canal correspondiente y los otros dos canales se establecen a cero. Luego, visualiza cada una de estas imágenes en subgráficos organizados en una sola fila."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NokgLFJ6Dx9a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Supongamos que 'im' es la imagen cargada previamente\n",
        "\n",
        "# Crear los subgráficos para mostrar los tres canales\n",
        "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))  # Crear una figura con 1 fila y 3 columnas de subgráficos\n",
        "\n",
        "# Iterar sobre los 3 canales (rojo, verde y azul)\n",
        "for c, ax in zip(range(3), axs):\n",
        "    tmp_im = np.zeros(im.shape, dtype=\"uint8\")  # Crear una imagen vacía del mismo tamaño que 'im'\n",
        "    tmp_im[:,:,c] = im[:,:,c]  # Asignar solo el canal 'c' a la imagen temporal (rojo, verde o azul)\n",
        "\n",
        "    ax.imshow(tmp_im)  # Mostrar la imagen con el canal 'c'\n",
        "    ax.set_axis_off()  # Desactivar los ejes para una visualización más limpia\n",
        "\n",
        "plt.tight_layout()  # Ajustar el espacio entre los subgráficos\n",
        "plt.show()  # Mostrar la figura completa\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSKl25BM0ii4"
      },
      "source": [
        "\n",
        "Cuando se utiliza imshow de matplotlib [imshow](http://matplotlib.org/api/axes_api.html#matplotlib.axes.Axes.imshow)  para mostrar imágenes, es importante tener en cuenta qué tipo de datos se está utilizando, ya que el mapeo de colores depende del tipo de datos: si se utiliza un tipo float, los valores se mapean al rango 0-1, por lo que necesitamos convertir a tipo \"uint8\" para obtener el comportamiento esperado. Se puede encontrar una buena discusión sobre este tema aquí.[here](http://stackoverflow.com/questions/24739769/matplotlib-imshow-plots-different-if-using-colormap-or-rgb-array).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8On6uSMZD-pr"
      },
      "source": [
        "## <font color=\"red\">6.11Transformaciones de Color: Normalización, rotación 3D y desnormalización de una imagen\n",
        "Representando el color de esta manera, podemos pensar en cada píxel como un punto en un espacio tridimensional. Al considerar el color de esta forma, podemos aplicar diversas transformaciones al \"punto\" de color. Un ejemplo interesante de estas es \"rotar\" el color.\n",
        "\n",
        "Hay algunas sutilezas: los colores legales existen oficialmente como puntos enteros en un cubo tridimensional con lados de longitud 255. Es posible que una rotación pueda empujar un punto fuera de este cubo. Para solucionar esto, aplico una transformación sigmoide a los datos, un mapeo del rango 0-1 a la línea real completa. Después de aplicar esta transformación, aplicamos la matriz de rotación y luego transformamos de nuevo al espacio de color.\n",
        "\n",
        "La matriz de rotación se aplica píxel por píxel a la imagen utilizando la función de notación de Einstein de numpy, que no había utilizado antes, pero hace que la operación sea concisa.\n",
        "\n",
        "Este código realiza una serie de transformaciones sobre una imagen: normaliza los valores de los píxeles de la imagen, aplica una rotación 3D sobre ella y luego desnormaliza la imagen transformada. La rotación se realiza alrededor del eje X en un espacio tridimensional, utilizando una matriz de rotación. La imagen es visualizada después de la desnormalización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcXLy5bwFK19"
      },
      "source": [
        "## <font color=\"red\">6.12Funciones de normalización y desnormalización:\n",
        "\n",
        "### `do_normalise(im)`\n",
        "Esta función normaliza la imagen a un rango diferente utilizando la fórmula:\n",
        "\n",
        "$$\n",
        "f(x) = -\\log\\left( \\frac{1}{\\left( \\frac{1 + \\text{imagen}}{257} \\right) - 1} \\right)\n",
        "$$\n",
        "\n",
        "Lo que hace es transformar los valores de los píxeles en un espacio logarítmico para cambiar su distribución.\n",
        "\n",
        "### `undo_normalise(im)`\n",
        "Esta función desnormaliza la imagen, llevando los valores de vuelta a su rango original utilizando la fórmula inversa:\n",
        "\n",
        "$$\n",
        "f^{-1}(x) = \\left( 1 + \\frac{1}{e^{-x} + 1} \\right) \\times 257\n",
        "$$\n",
        "\n",
        "Esta fórmula revierte la transformación logarítmica aplicada por la función `do_normalise`.\n",
        "\n",
        "---\n",
        "\n",
        "## Función de matriz de rotación 3D:\n",
        "\n",
        "### `rotation_matrix(theta)`\n",
        "Esta función genera una matriz de rotación en 3D alrededor del eje X con un ángulo $\\theta$. Se utiliza la fórmula estándar para la rotación de un vector en 3D en torno al eje X:\n",
        "\n",
        "$$\n",
        "R = \\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "0 & \\cos(\\theta) & -\\sin(\\theta) \\\\\n",
        "0 & \\sin(\\theta) & \\cos(\\theta)\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "La matriz generada se usará para rotar los valores de los píxeles en 3D.\n",
        "\n",
        "---\n",
        "\n",
        "## Transformaciones y visualización:\n",
        "\n",
        "1. **Normalización**:  \n",
        "   `im_normed = do_normalise(im)` normaliza la imagen original.\n",
        "\n",
        "2. **Rotación 3D**:  \n",
        "   `im_rotated = np.einsum(\"ijk,lk->ijl\", im_normed, rotation_matrix(np.pi))` aplica la rotación 3D a los píxeles de la imagen normalizada. `np.einsum` realiza una multiplicación matricial eficiente.\n",
        "\n",
        "3. **Desnormalización**:  \n",
        "   `im2 = undo_normalise(im_rotated)` desnormaliza la imagen rotada para restaurarla a su espacio de píxeles original.\n",
        "\n",
        "4. **Visualización**:  \n",
        "   `plti(im2)` usa la función `plti` para mostrar la imagen resultante después de la desnormalización.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBfYAEte0ii4"
      },
      "outputs": [],
      "source": [
        "\n",
        "def do_normalise(im):\n",
        "    epsilon = 1e-8  # Valor pequeño para evitar divisiones por cero\n",
        "    return -np.log(1 / ((1 + im) / 257 + epsilon) - 1)\n",
        "\n",
        "def undo_normalise(im):\n",
        "    \"\"\"\n",
        "    Desnormaliza la imagen utilizando la fórmula inversa de la normalización.\n",
        "    \"\"\"\n",
        "    return (1 + 1 / (np.exp(-im) + 1) * 257).astype(\"uint8\")\n",
        "\n",
        "def rotation_matrix(theta):\n",
        "    \"\"\"\n",
        "    Genera una matriz de rotación 3D alrededor del eje X por un ángulo 'theta'.\n",
        "    \"\"\"\n",
        "    return np.c_[\n",
        "        [1, 0, 0],\n",
        "        [0, np.cos(theta), -np.sin(theta)],\n",
        "        [0, np.sin(theta), np.cos(theta)]\n",
        "    ]\n",
        "\n",
        "# Aplicar normalización a la imagen\n",
        "im_normed = do_normalise(im)\n",
        "\n",
        "# Rotar la imagen en 3D usando la matriz de rotación alrededor del eje X\n",
        "im_rotated = np.einsum(\"ijk,lk->ijl\", im_normed, rotation_matrix(np.pi))\n",
        "\n",
        "# Desnormalizar la imagen después de la rotación\n",
        "im2 = undo_normalise(im_rotated)\n",
        "\n",
        "print('Imagen Original')\n",
        "\n",
        "\n",
        "plti(im,5)\n",
        "\n",
        "print('Imagen Normalizada')\n",
        "\n",
        "plti(np.clip(im_normed, 0, 1),5)\n",
        "\n",
        "print('Imagen Rotada')\n",
        "plti(np.clip(im_rotated, 0, 1) ,5)\n",
        "\n",
        "# Visualizar la imagen resultante después de la desnormalización\n",
        "print('Imagen Desnormalizada')\n",
        "plti(im2,5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vnu2OCJK0ii4"
      },
      "source": [
        "## <font color=\"red\"> 6.13 Rotación contínua de colores\n",
        "\n",
        "El siguiente código utiliza FuncAnimation de Matplotlib para crear una animación que rota una imagen en 3D mediante la rotación de sus canales de color.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTHjO5N80ii5"
      },
      "outputs": [],
      "source": [
        "from matplotlib.animation import FuncAnimation\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Crear la figura y el eje\n",
        "fig, ax = plt.subplots(figsize=(5,8))\n",
        "\n",
        "# Función de actualización para la animación\n",
        "def update(i):\n",
        "    # Normalizar la imagen\n",
        "    im_normed = do_normalise(im)\n",
        "\n",
        "    # Rotación de la imagen\n",
        "    im_rotated = np.einsum(\"ijk,lk->ijl\", im_normed, rotation_matrix(i * np.pi/10))\n",
        "\n",
        "    # Desnormalizar la imagen\n",
        "    im2 = undo_normalise(im_rotated)\n",
        "\n",
        "    # Asegurarse de que la imagen esté en un rango adecuado para mostrarla\n",
        "    im2 = np.clip(im2, 0, 255).astype(np.uint8)  # Limitar entre 0 y 255\n",
        "\n",
        "    # Mostrar la imagen en el eje\n",
        "    ax.imshow(im2)\n",
        "    ax.set_title(\"Angulo: {}*pi/10\".format(i), fontsize=20)\n",
        "    ax.set_axis_off()\n",
        "\n",
        "# Crear la animación\n",
        "anim = FuncAnimation(fig, update, frames=np.arange(0, 20), interval=50)\n",
        "\n",
        "# Guardar la animación como un archivo GIF\n",
        "anim.save('colour_rotation.gif', dpi=80, writer='imagemagick')\n",
        "\n",
        "# Cerrar la figura después de guardar la animación\n",
        "plt.close()\n",
        "\n",
        "# Mostrar el GIF en el cuaderno de Colab\n",
        "from IPython.display import Image\n",
        "Image(filename=\"colour_rotation.gif\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xULpXjrp0ii5"
      },
      "source": [
        "### <font color=\"blue\">6.13.1 A Escala de grises\n",
        "\n",
        "En el tema del color, también podemos transformar la imagen a escala de grises de manera sencilla. Hay varias formas de hacerlo, pero una forma directa es tomar la media ponderada del valor RGB de la imagen original:\n",
        "\n",
        "Método de Conversión a Escala de Grises\n",
        "\n",
        "\n",
        "Una forma común de convertir una imagen a escala de grises es usar una fórmula que considera la sensibilidad del ojo humano a los diferentes colores.\n",
        "\n",
        "Una fórmula común es:\n",
        "\n",
        "Gris=0.2989×𝑅+0.5870×𝐺+0.1140×𝐵\n",
        "\n",
        "\n",
        "Esto refleja que el ojo humano es más sensible al verde, seguido del rojo y menos al azul.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmWQm9PpLMMe"
      },
      "source": [
        "# <font color=\"blue\">6.13.2 Conversión de Imagen a Escala de Grises y Visualización\n",
        "\n",
        "Este código realiza la conversión de una imagen a escala de grises usando la fórmula estándar de luminosidad ponderada. La imagen se carga desde una ruta especificada, se convierte a escala de grises y luego se muestra usando `Matplotlib`.\n",
        "\n",
        "## Descripción\n",
        "\n",
        "* **Conversión a Escala de Grises**: Se utiliza la fórmula ponderada para convertir los valores de color RGB en valores de escala de grises.\n",
        "\n",
        "* **Mostrar la Imagen**: La imagen resultante se muestra utilizando `Matplotlib`, sin los ejes y con un título que describe la transformación.\n",
        "\n",
        "La fórmula utilizada para la conversión es:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUoNrzpD4S4p"
      },
      "outputs": [],
      "source": [
        "# Convertir la imagen a escala de grises utilizando la fórmula de luminosidad\n",
        "# Se utiliza una ponderación estándar para cada canal de color:\n",
        "# 0.2989 * Rojo + 0.5870 * Verde + 0.1140 * Azul\n",
        "grey_image = 0.2989 * im[:, :, 0] + 0.5870 * im[:, :, 1] + 0.1140 * im[:, :, 2]\n",
        "\n",
        "# Asegurarse de que los valores de la imagen estén en el rango adecuado de 0 a 255 (uint8)\n",
        "grey_image = grey_image.astype(np.uint8)  # Convertir a uint8 para representación correcta de la imagen\n",
        "\n",
        "# Mostrar la imagen en escala de grises utilizando Matplotlib\n",
        "# Se utiliza el mapa de colores 'gray' para representar la imagen en escala de grises\n",
        "plt.imshow(grey_image, cmap='gray')\n",
        "\n",
        "# Desactivar los ejes para que no se muestren en la visualización\n",
        "plt.axis('off')  # Desactivar ejes\n",
        "\n",
        "# Título que aparecerá en la imagen mostrada\n",
        "plt.title('Imagen en Escala de Grises')  # Agregar un título a la imagen\n",
        "\n",
        "# Mostrar la imagen\n",
        "plt.show()  # Mostrar la imagen en la pantalla\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPG62POu0ii6"
      },
      "source": [
        "# <font color=\"red\">6.14 Convolución\n",
        "Otra de las operaciones básicas que puedes aplicar a una imagen es la convolución.\n",
        "\n",
        "## <font color=\"blue\">6.14.1 Definición de Convolución\n",
        "\n",
        "La convolución es un operador matemático que combina dos funciones para producir una tercera función.\n",
        "\n",
        "En el contexto de imágenes, se utiliza para aplicar filtros o kernels a la imagen original. E\n",
        "\n",
        "Este proceso permite realizar diversas tareas, como suavizado, detección de bordes y realce de características.\n",
        "\n",
        "$C(x,y) = \\int dx'dy' I(x + x',y + y') W(x',y')$\n",
        "\n",
        "\n",
        "Donde\n",
        "* 𝐶 es la imagen convolucionada,\n",
        "* 𝐼 es la imagen original\n",
        "* 𝑊 es una función de ventana.\n",
        "\n",
        "Esencialmente, estamos reemplazando cada píxel con una suma ponderada de píxeles cercanos.\n",
        "\n",
        "### <font color=\"blue\">6.14.2 Reducción de la Imagen\n",
        "\n",
        "\n",
        "Debido a que las convoluciones pueden ser costosas en términos computacionales, comenzamos por reducir el tamaño de la imagen.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OoKOgnK6e6X"
      },
      "source": [
        "# <font color=\"red\"> 6.15 Kernel\n",
        "Un kernel (o filtro) es una matriz pequeña que se mueve a través de la imagen. El tamaño más común de un kernel es 3x3, pero también existen kernels de tamaños mayores como 5x5 o 7x7, dependiendo de la aplicación.\n",
        "\n",
        "El kernel se coloca sobre la imagen y, para cada píxel, realiza una multiplicación elemento a elemento con la vecindad de píxeles de la imagen, seguida de una suma de esos productos.\n",
        "\n",
        "En la  siguiente imagen observamos un kernel de 3x3, que toma el subarreglo de 3x3 de la imagen original y hacer una operación de multiplicación y suma y el resultado lo pone en la imagen de salida. Como veremos más adelante aparecentemente pierde resolución, pero depede del kernel resaltamos contornos, formas ,etc.\n",
        "\n",
        "![imagen](https://github.com/adiacla/bigdata/blob/master/kernel.png?raw=true)\n",
        "\n",
        "\n",
        "Es esta imagen se aprecia tambien con detalle dicha transformación\n",
        "\n",
        "![imagen](https://github.com/adiacla/bigdata/blob/master/kernel2.png?raw=true)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ7TF6R2RvZz"
      },
      "source": [
        "##<font color=\"blue\">6.15.1 Tipos de Kernel\n",
        "\n",
        "Los kernels se usan para diferentes tareas en procesamiento de imágenes. Algunos de los más comunes son:\n",
        "\n",
        "**Filtro de suavizado (Blur):** Suaviza la imagen al promediar los píxeles vecinos.\n",
        "\n",
        "Ejemplo de un kernel de suavizado 3x3:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "\\frac{1}{9} & \\frac{1}{9} & \\frac{1}{9} \\\\\n",
        "\\frac{1}{9} & \\frac{1}{9} & \\frac{1}{9} \\\\\n",
        "\\frac{1}{9} & \\frac{1}{9} & \\frac{1}{9}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "Filtro de detección de bordes (Edge Detection): Detecta los bordes de los objetos dentro de una imagen. Un ejemplo es el filtro de Sobel.\n",
        "\n",
        "Kernel de detección de bordes en la dirección horizontal (Sobel):\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "-1 &  0 &  1 \\\\\n",
        "-2 &  0 &  2 \\\\\n",
        "-1 &  0 &  1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Filtro de nitidez (Sharpening): Aumenta el contraste de la imagen, destacando las áreas de alta frecuencia.\n",
        "\n",
        "Ejemplo de un kernel de nitidez:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        " 0 & -1 &  0 \\\\\n",
        "-1 &  5 & -1 \\\\\n",
        " 0 & -1 &  0\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "Algunos otros kernel y sus aplicaciones las puede observar en la siguiente imagen.\n",
        "\n",
        "![imagen](https://github.com/adiacla/bigdata/blob/master/kernel3.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9FzK4caUGA2"
      },
      "source": [
        "## <font color=\"red\"> 6.16 Reducción de Tamaño de la Imagen y Aplicación de un Filtro de Desenfoque (Convolución)\n",
        "\n",
        "Este código realiza dos operaciones en una imagen:\n",
        "\n",
        "Reducción de Tamaño: Reduce el tamaño de la imagen a la mitad, lo que puede ser útil cuando se necesita reducir la carga computacional o cuando se trabaja con imágenes de gran tamaño.\n",
        "\n",
        "\n",
        "Convolución con un Filtro de Desenfoque: Aplica un filtro de desenfoque utilizando una matriz kernel de promedio. Esto suaviza la imagen, lo que puede ser útil para eliminar detalles finos y reducir el ruido.\n",
        "\n",
        "Kernel de Promedio: El filtro utilizado en este caso es un filtro de promedio (o desenfoque), que es una matriz de tamaño  5×5 donde todos los valores son 1. El valor 25 es el tamaño total de la matriz 5×5.\n",
        "\n",
        "Esto asegura que al aplicar este filtro, cada píxel en la imagen es reemplazado por el promedio de sus píxeles vecinos en una vecindad de 5×5.\n",
        "\n",
        "Esta operación suaviza la imagen, ayudando a reducir detalles y ruido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bYhMyNm6jAd"
      },
      "outputs": [],
      "source": [
        "# Reducir el tamaño de la imagen (por ejemplo, la mitad)\n",
        "\n",
        "reduced_image = cv.resize(im, (img_rgb.shape[1] // 2, img_rgb.shape[0] // 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xokFDBeWU3wS"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Aplicar una convolución simple (por ejemplo, un filtro de desenfoque)\n",
        "\n",
        "#Crear el filtro\n",
        "\n",
        "kernel = np.ones((3, 3), np.float32) / 10  # Kernel de promedio\n",
        "kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo02O_h8VFnK"
      },
      "source": [
        "Este código realiza una convolución en una imagen que previamente ha sido reducida de tamaño, utilizando un filtro de desenfoque. A continuación, se muestran tanto la imagen original reducida como la imagen resultante de la convolución. Se utiliza la función cv2.filter2D() para aplicar el filtro a la imagen, que en este caso es un filtro de promedio o desenfoque.\n",
        "\n",
        "Finalmente, se visualizan ambas imágenes (original reducida y convolucionada) para comparar el efecto del filtro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bR_GEqzTfoWQ"
      },
      "outputs": [],
      "source": [
        "# Aplicar la convolución con el filtro definido (filtro de desenfoque)\n",
        "# La función cv2.filter2D toma la imagen y el kernel para aplicar la operación de convolución.\n",
        "# El valor -1 en el segundo parámetro indica que la imagen de salida tendrá el mismo tipo de datos que la imagen de entrada.\n",
        "convoluted_image = cv2.filter2D(reduced_image, -1, kernel)\n",
        "\n",
        "# Mostrar la imagen original reducida y la imagen convolucionada\n",
        "# Crear una figura con dos subgráficas (una para cada imagen)\n",
        "plt.figure(figsize=(5, 5))\n",
        "\n",
        "# Subgráfica 1: Imagen Reducida\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(reduced_image)\n",
        "plt.title('Imagen Reducida')  # Título de la primera imagen\n",
        "plt.axis('off')  # Desactivar los ejes para mejor visualización\n",
        "\n",
        "# Subgráfica 2: Imagen Convolucionada (con el filtro de desenfoque)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(convoluted_image)\n",
        "plt.title('Imagen Convolucionada')  # Título de la imagen resultante\n",
        "plt.axis('off')  # Desactivar los ejes para mejor visualización\n",
        "\n",
        "# Ajustar el espaciado entre las subgráficas\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrar la figura con ambas imágenes\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBm8MVGF8NSs"
      },
      "outputs": [],
      "source": [
        "convoluted_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy1HxVP4Vm21"
      },
      "source": [
        "##<font color=\"red\">6.17 Reducción de Tamaño de la Imagen Usando scipy.ndimage.zoom\n",
        "\n",
        "Este código utiliza la función zoom de Scipy para reducir el tamaño de la imagen a un 20% de su tamaño original. La función zoom permite realizar un cambio de tamaño de la imagen de manera eficiente, escalando la imagen en los tres canales de color (rojo, verde y azul) de acuerdo a los factores dados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Zqsaknl30ii6"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import zoom\n",
        "\n",
        "# Reducir la imagen a un 20% de su tamaño original\n",
        "# La función zoom recibe tres parámetros: la imagen original, un factor de escala para cada dimensión.\n",
        "# El primer valor (0.2) escala las dimensiones (alto y ancho) al 20% de su tamaño original.\n",
        "# El segundo valor (0.2) también escala la altura y la anchura.\n",
        "# El valor 1 indica que no se cambia el número de canales de color (rojo, verde, azul).\n",
        "im_small = zoom(im, (0.2, 0.2, 1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q34OY52attvM"
      },
      "source": [
        "Este código visualiza tanto la imagen original como la imagen reducida (al 20% de su tamaño original) para comparar cómo cambia la resolución después de aplicar la reducción de tamaño con la función zoom de Scipy. Se utilizan subgráficas en Matplotlib para mostrar ambas imágenes lado a lado, lo que permite una comparación visual directa de las dos versiones de la imagen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVnd0IRN6_2c"
      },
      "outputs": [],
      "source": [
        "# Mostrar la imagen original y la imagen reducida\n",
        "# Crear una figura con dos subgráficas (una para cada imagen)\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Imagen original\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(im)\n",
        "plt.title('Imagen Original')  # Título de la primera imagen\n",
        "plt.axis('on')  # Desactivar los ejes para mejor visualización\n",
        "\n",
        "# Imagen reducida\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(im_small)\n",
        "plt.title('Imagen Reducida (20%)')  # Título de la imagen reducida\n",
        "plt.axis('on')  # Desactivar los ejes para mejor visualización\n",
        "\n",
        "# Ajustar el espaciado entre las subgráficas para evitar solapamientos\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrar la figura con ambas imágenes\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qkbsj5yBV8m7"
      },
      "source": [
        "Las imagenes anteriores aparentemente se ven del mismo tamaño.\n",
        "En Google Colab, cuando visualizas imágenes usando matplotlib o cv2, es posible que el entorno ajuste automáticamente el tamaño de las imágenes para adaptarse al área de visualización disponible. Esto puede hacer que las imágenes se vean del mismo tamaño, incluso si en realidad tienen diferentes dimensiones.\n",
        "\n",
        "# <font color=\"blue\">6.17.1 Ver tamaños reales\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hh5ZQRw5WvGA"
      },
      "outputs": [],
      "source": [
        "# Calcular el tamaño de la figura basado en las dimensiones de la imagen\n",
        "# (para mantener la proporción original de la imagen)\n",
        "fig_width = im.shape[1] / 100  # 100 píxeles por pulgada\n",
        "fig_height = im.shape[0] / 100  # 100 píxeles por pulgada\n",
        "\n",
        "# Crear la figura con el tamaño ajustado\n",
        "plt.figure(figsize=(fig_width, fig_height))\n",
        "\n",
        "# Mostrar la imagen original\n",
        "plt.imshow(im)\n",
        "plt.title('Imagen Original')\n",
        "plt.axis('off')  # Desactivar los ejes\n",
        "plt.show()\n",
        "\n",
        "# Crear la figura para la imagen reducida\n",
        "fig_width_small = im_small.shape[1] / 100\n",
        "fig_height_small = im_small.shape[0] / 100\n",
        "plt.figure(figsize=(fig_width_small, fig_height_small))\n",
        "\n",
        "# Mostrar la imagen reducida\n",
        "plt.imshow(im_small)\n",
        "plt.title('Imagen Reducida (20%)')\n",
        "plt.axis('off')  # Desactivar los ejes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfTGXUQJXHuk"
      },
      "source": [
        "## <font color=\"blue\">6.17.2 Visualización de Imagen Original y Reducida con Ajuste de Proporciones\n",
        "\n",
        "Este código carga una imagen, la reduce al 20% de su tamaño original usando scipy.ndimage.zoom, y luego visualiza ambas imágenes (la original y la reducida) en una misma figura. Para asegurarse de que la imagen reducida mantenga sus proporciones correctas, se ajusta el aspecto de la subgráfica correspondiente, utilizando la relación de las dimensiones de la imagen reducida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqHOQpJ_7Sdk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "# Cargar la imagen (asegúrate de que la variable `im` ya esté definida)\n",
        "# im = cv2.imread('ruta_a_la_imagen.jpg')  # Ejemplo de carga\n",
        "\n",
        "# Reducir la imagen a un 20% de su tamaño original\n",
        "im_small = zoom(im, (0.2, 0.2, 1))  # Reducimos el tamaño de la imagen al 20% en alto y ancho\n",
        "\n",
        "# Mostrar la imagen original y la imagen reducida\n",
        "plt.figure(figsize=(12, 6))  # Ajustamos el tamaño de la figura para que ambas imágenes quepan cómodamente\n",
        "\n",
        "# Imagen original\n",
        "plt.subplot(1, 2, 1)  # Configuramos la primera subgráfica\n",
        "plt.imshow(im)  # Mostramos la imagen original\n",
        "plt.title('Imagen Original')  # Título de la imagen original\n",
        "plt.axis('off')  # Desactivamos los ejes para mejorar la visualización\n",
        "\n",
        "# Imagen reducida\n",
        "plt.subplot(1, 2, 2)  # Configuramos la segunda subgráfica\n",
        "plt.imshow(im_small)  # Mostramos la imagen reducida\n",
        "plt.title('Imagen Reducida (20%)')  # Título de la imagen reducida\n",
        "plt.axis('off')  # Desactivamos los ejes para mejorar la visualización\n",
        "\n",
        "# Ajustar el tamaño de la figura basado en las dimensiones de la imagen reducida\n",
        "# Establecemos la relación de aspecto de la imagen reducida\n",
        "plt.subplot(1, 2, 2).set_aspect(im_small.shape[0] / im_small.shape[1])\n",
        "\n",
        "# Ajustar el espaciado entre subgráficas para evitar solapamientos\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrar la figura con las imágenes\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H82wATCJ0ii6"
      },
      "source": [
        "# <font color=\"red\">6.18 Aplicación de Filtro Uniforme (Desenfoque) en una Imagen Reducida\n",
        "\n",
        "\n",
        "Este código toma una imagen, la reduce al 20% de su tamaño original utilizando la función zoom de scipy.ndimage, y luego aplica un filtro uniforme (desenfoque) usando uniform_filter. Finalmente, se visualizan tanto la imagen reducida como la imagen desenfocada en una figura con dos subgráficas.\n",
        "\n",
        "\n",
        "##<font color=\"blue\">6.18.1 Ventana Uniforme\n",
        "Una ventana uniforme (o kernel de promedio) es un filtro que asigna el mismo peso a todos los píxeles en el área del kernel. Esto significa que cada píxel en la imagen resultante es el promedio de los píxeles en su vecindad.\n",
        "\n",
        "###<font color=\"blue\">6.18.2 Matriz de un Filtro Uniforme 5x5:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "\\frac{1}{25} & \\frac{1}{25} & \\frac{1}{25} & \\frac{1}{25} & \\frac{1}{25} \\\\\n",
        "\\frac{1}{25} & \\frac{1}{25} & \\frac{1}{25} & \\frac{1}{25} & \\frac{1}{25} \\\\\n",
        "\\frac{1}{25} & \\frac{1}{25} & \\frac{1}{25} & \\frac{1}{25} & \\frac{1}{25} \\\\\n",
        "\\frac{1}{25} & \\frac{1}{25} & \\frac{1}{25} & \\frac{1}{25} & \\frac{1}{25} \\\\\n",
        "\\frac{1}{25} & \\frac{1}{25} & \\frac{1}{25} & \\frac{1}{25} & \\frac{1}{25}\n",
        "\\end{bmatrix}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnvHaLTK7nAx"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import uniform_filter\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "# Cargar la imagen (asegúrate de que la variable `im` ya esté definida)\n",
        "# im = cv2.imread('ruta_a_la_imagen.jpg')  # Ejemplo de carga\n",
        "\n",
        "# Reducir la imagen a un 20% de su tamaño original\n",
        "im_small = zoom(im, (0.2, 0.2, 1))  # Reducimos el tamaño de la imagen al 20% en alto y ancho\n",
        "\n",
        "# Aplicar un filtro uniforme (desenfoque) con un kernel de tamaño 5x5\n",
        "blurred_image = uniform_filter(im_small, size=5)  # Tamaño del kernel\n",
        "\n",
        "# Mostrar la imagen original y la imagen desenfocada\n",
        "plt.figure(figsize=(12, 6))  # Ajustamos el tamaño de la figura para que ambas imágenes quepan cómodamente\n",
        "\n",
        "# Imagen reducida\n",
        "plt.subplot(1, 2, 1)  # Configuramos la primera subgráfica\n",
        "plt.imshow(im_small)  # Mostramos la imagen reducida\n",
        "plt.title('Imagen Reducida')  # Título de la imagen reducida\n",
        "plt.axis('off')  # Desactivamos los ejes para mejorar la visualización\n",
        "\n",
        "# Imagen desenfocada\n",
        "plt.subplot(1, 2, 2)  # Configuramos la segunda subgráfica\n",
        "plt.imshow(blurred_image)  # Mostramos la imagen desenfocada\n",
        "plt.title('Imagen Desenfocada')  # Título de la imagen desenfocada\n",
        "plt.axis('off')  # Desactivamos los ejes para mejorar la visualización\n",
        "\n",
        "# Ajustar el espaciado entre subgráficas para evitar solapamientos\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrar la figura con las imágenes\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oo0IqJn0ii7"
      },
      "source": [
        "#<font color=\"red\"> 6.19 Otros filtros para Desenfoque de Imágenes\n",
        "Para desenfocar una imagen, hay una variedad de ventanas y funciones que se pueden utilizar. Las más comunes son la ventana uniforme, la ventana gaussiana y el filtro de mediana. Para entender cómo afectan cada uno de estos filtros a una imagen, aplicaremos todos ellos a nuestra imagen, utilizando diferentes tamaños de ventana.\n",
        "\n",
        "##<font color=\"blue\">6.19.1 Ventana Uniforme:\n",
        "\n",
        "Como vimosanteriormente, éste suma los píxeles en un área determinada y los promedia, dando el mismo peso a todos los píxeles. Es un enfoque simple pero efectivo para el desenfoque.\n",
        "\n",
        "##<font color=\"blue\">6.19.2 Ventana Gaussiana:\n",
        "\n",
        "Asigna pesos diferentes a los píxeles, donde los píxeles más cercanos al centro tienen un mayor peso. Esto crea un desenfoque más suave en comparación con la ventana uniforme.\n",
        "\n",
        "##<font color=\"blue\">6.19.3 Filtro de Mediana:\n",
        "\n",
        "Reemplaza cada píxel con la mediana de los píxeles en su vecindad. Esto es útil para eliminar el ruido mientras se preservan los bordes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmgZNl0mYV3L"
      },
      "source": [
        "## <font color=\"blue\">6.19.4 Realce de Border\n",
        "\n",
        "Para realizar un realce de bordes en la imagen, puedes usar un filtro de detección de bordes como el filtro Sobel o el filtro Laplaciano. Estos filtros ayudan a resaltar las áreas donde ocurren cambios bruscos en la intensidad de los píxeles, es decir, los bordes de los objetos.\n",
        "\n",
        "Dado que este es uno de los procesos de convolución más importante en RNN, vamos a presentar cómo realizar el realce de bordes utilizando un filtro Sobel y luego aplicar un filtro de realce de bordes utilizando scipy.ndimage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6drdibI1YWIG"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import zoom\n",
        "from scipy.ndimage import sobel\n",
        "\n",
        "# Cargar la imagen (asegúrate de que la variable `im` ya esté definida)\n",
        "# im = cv2.imread('ruta_a_la_imagen.jpg')  # Ejemplo de carga\n",
        "\n",
        "# Reducir la imagen a un 20% de su tamaño original\n",
        "im_small = zoom(im, (0.2, 0.2, 1))\n",
        "\n",
        "# Convertir la imagen a tipo de dato float32 para evitar errores en la convolución\n",
        "im_small = im_small.astype(np.float32)\n",
        "\n",
        "# Aplicar el filtro Sobel para detectar bordes en la dirección X y Y\n",
        "sobel_x = sobel(im_small, axis=0)  # Sobel en el eje X\n",
        "sobel_y = sobel(im_small, axis=1)  # Sobel en el eje Y\n",
        "\n",
        "# Combinar los bordes de ambas direcciones (X y Y)\n",
        "edges = np.hypot(sobel_x, sobel_y)  # Magnitud del gradiente\n",
        "\n",
        "# Normalizar para que los valores estén entre 0 y 1\n",
        "edges = edges / np.max(edges)\n",
        "\n",
        "# Mostrar la imagen original y la imagen con realce de bordes\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "\n",
        "# Imagen con realce de bordes\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(np.clip(edges,0, 1), cmap='gray', vmin=0, vmax=1)  # Normalización para valores entre 0 y 1\n",
        "plt.title('Realce de Bordes')\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKFSB1_H0ii6"
      },
      "outputs": [],
      "source": [
        "#Este código define una función que aplica una convolución a una imagen en todos sus canales de color (RGB) utilizando un kernel (ventana) dado.\n",
        "from scipy.signal import convolve2d\n",
        "\n",
        "def convolve_all_colours(im, window):\n",
        "    \"\"\"\n",
        "    Convolves im with window, over all three colour channels\n",
        "    \"\"\"\n",
        "    ims = []\n",
        "    for d in range(3):  # Iterar sobre los 3 canales de color\n",
        "        im_conv_d = convolve2d(im[:,:,d], window, mode=\"same\", boundary=\"symm\")\n",
        "        ims.append(im_conv_d)  # Guardar la imagen convolucionada\n",
        "\n",
        "    im_conv = np.stack(ims, axis=2).astype(\"uint8\")  # Combinar los canales\n",
        "    return im_conv\n",
        "\n",
        "# Definir el tamaño del kernel\n",
        "n = 10\n",
        "window = np.ones((n, n))  # Crear una ventana uniforme\n",
        "window /= np.sum(window)  # Normalizar la ventana\n",
        "\n",
        "# Aplicar la convolución y mostrar el resultado\n",
        "plti(convolve_all_colours(im_small, window),6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JVPmE4nWquR"
      },
      "source": [
        "##<font color=\"red\">6.20 Convolución de imagen sobre los tres canales de color con un kernel definido\n",
        "\n",
        "Este código realiza una convolución de una imagen en los tres canales de color (rojo, verde y azul) utilizando un kernel definido.\n",
        "\n",
        "La función convolve_all_colours aplica una operación de convolución a la imagen, procesando cada uno de los canales de color por separado y luego recombinándolos.\n",
        "\n",
        "El kernel que se utiliza en este caso es un filtro uniforme de tamaño n x n que se normaliza para asegurar que la suma de los valores del kernel sea igual a 1, lo que ayuda a mantener la intensidad de la imagen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cadWQ2g99tBL"
      },
      "outputs": [],
      "source": [
        "# Importamos la función de convolución 2D de la biblioteca scipy\n",
        "from scipy.signal import convolve2d\n",
        "\n",
        "# Función que realiza la convolución sobre los tres canales de color de la imagen\n",
        "def convolve_all_colours(im, window):\n",
        "    \"\"\"\n",
        "    Realiza la convolución de la imagen sobre los tres canales de color (RGB)\n",
        "    utilizando un kernel (ventana) dado.\n",
        "    \"\"\"\n",
        "    ims = []  # Lista para almacenar las imágenes convolucionadas de cada canal\n",
        "\n",
        "    # Iteramos sobre los 3 canales de color de la imagen (Rojo, Verde y Azul)\n",
        "    for d in range(3):\n",
        "        # Aplicamos la convolución 2D al canal de color actual\n",
        "        im_conv_d = convolve2d(im[:,:,d], window, mode=\"same\", boundary=\"symm\")\n",
        "        ims.append(im_conv_d)  # Guardamos la imagen convolucionada del canal actual\n",
        "\n",
        "    # Recombinamos los canales convolucionados en una sola imagen\n",
        "    im_conv = np.stack(ims, axis=2).astype(\"uint8\")  # Convertimos a tipo uint8\n",
        "    return im_conv  # Retornamos la imagen convolucionada\n",
        "\n",
        "# Definir el tamaño del kernel (filtro)\n",
        "n = 10\n",
        "\n",
        "# Crear una ventana uniforme de tamaño n x n (filtro promedio)\n",
        "window = np.ones((n, n))\n",
        "\n",
        "# Normalizamos el kernel para que la suma de sus elementos sea 1, lo que evita aumentar la intensidad de la imagen\n",
        "window /= np.sum(window)\n",
        "\n",
        "# Aplicamos la convolución a la imagen (im_small) usando el kernel creado\n",
        "# `convolve_all_colours` realiza la convolución sobre los 3 canales de color (RGB)\n",
        "plti(convolve_all_colours(im_small, window),8)  # Mostramos la imagen convolucionada con plti\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIpD7cBuXH1F"
      },
      "source": [
        "##<font color=\"red\">6.21 Aplicación de Filtros de Media, Gaussiano y Mediana en Imágenes RGB\n",
        "\n",
        "Este código aplica tres tipos de filtros (media, gaussiano y mediana) a una imagen en sus tres canales de color (rojo, verde y azul) usando diferentes tamaños de ventana.\n",
        "\n",
        "Los filtros se aplican sobre una imagen reducida (im_small) y los resultados se muestran en una serie de subgráficas.\n",
        "\n",
        "Se utilizan ventanas de diferentes tamaños para comparar cómo cambia el efecto de los filtros en la imagen:\n",
        "\n",
        "* **Filtro de Media (Mean Filter):**\n",
        " Suaviza la imagen promediando los valores de los píxeles en una vecindad dada.\n",
        "\n",
        "* **Filtro Gaussiano (Gaussian Filter)**: Suaviza la imagen aplicando un filtro basado en una distribución normal (Gaussiana).\n",
        "\n",
        "* **Filtro de Mediana (Median Filter):** El valor de cada píxel se reemplaza por la mediana de los valores en la vecindad.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9POxZZL0ii7"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import median_filter\n",
        "\n",
        "def make_gaussian_window(n, sigma=1):\n",
        "    \"\"\"\n",
        "    Crea una ventana cuadrada de tamaño n x n con pesos de una distribución gaussiana\n",
        "    con desviación estándar sigma.\n",
        "    \"\"\"\n",
        "    # nn define el tamaño de la vecindad alrededor de cada píxel\n",
        "    nn = int((n-1)/2)\n",
        "    # Se crea una matriz de distancias euclidianas al cuadrado\n",
        "    a = np.asarray([[x**2 + y**2 for x in range(-nn,nn+1)] for y in range(-nn,nn+1)])\n",
        "    # Se genera la matriz con valores gaussianos (de acuerdo con la fórmula de la distribución)\n",
        "    return np.exp(-a/(2*sigma**2))\n",
        "\n",
        "def median_filter_all_colours(im_small, window_size):\n",
        "    \"\"\"\n",
        "    Aplica un filtro de mediana a todos los canales de color de la imagen\n",
        "    \"\"\"\n",
        "    ims = []\n",
        "    for d in range(3):  # Iterar sobre los 3 canales de color (Rojo, Verde, Azul)\n",
        "        # Aplicar el filtro de mediana 2D en cada canal de la imagen\n",
        "        im_conv_d = median_filter(im_small[:,:,d], size=(window_size, window_size))\n",
        "        ims.append(im_conv_d)  # Almacenar la imagen convolucionada por cada canal\n",
        "\n",
        "    # Recombinamos los canales procesados\n",
        "    im_conv = np.stack(ims, axis=2).astype(\"uint8\")\n",
        "    return im_conv  # Retornar la imagen procesada\n",
        "\n",
        "# Diferentes tamaños de ventana para probar con cada filtro\n",
        "window_sizes = [9, 17, 33, 65]\n",
        "\n",
        "# Crear una figura con subgráficas para mostrar los resultados\n",
        "fig, axs = plt.subplots(nrows=3, ncols=len(window_sizes), figsize=(15, 15));\n",
        "\n",
        "# Filtro de media\n",
        "for w, ax in zip(window_sizes, axs[0]):\n",
        "    window = np.ones((w, w))  # Crear un kernel de ventana uniforme\n",
        "    window /= np.sum(window)  # Normalizar la ventana\n",
        "    # Aplicar el filtro de media sobre los 3 canales de color\n",
        "    ax.imshow(convolve_all_colours(im_small, window))\n",
        "    ax.set_title(\"Mean Filter: window size: {}\".format(w))  # Título con el tamaño de la ventana\n",
        "    ax.set_axis_off()  # Desactivar el eje\n",
        "\n",
        "# Filtro Gaussiano\n",
        "for w, ax in zip(window_sizes, axs[1]):\n",
        "    # Crear un filtro gaussiano con el tamaño de ventana correspondiente\n",
        "    window = make_gaussian_window(w, sigma=w)\n",
        "    window /= np.sum(window)  # Normalizar la ventana\n",
        "    # Aplicar el filtro gaussiano sobre los 3 canales de color\n",
        "    ax.imshow(convolve_all_colours(im_small, window))\n",
        "    ax.set_title(\"Gaussian Filter: window size: {}\".format(w))\n",
        "    ax.set_axis_off()\n",
        "\n",
        "# Filtro de mediana\n",
        "for w, ax in zip(window_sizes, axs[2]):\n",
        "    # Aplicar el filtro de mediana sobre los 3 canales de color con el tamaño de ventana correspondiente\n",
        "    ax.imshow(median_filter_all_colours(im_small, w))\n",
        "    ax.set_title(\"Median Filter: window size: {}\".format(w))\n",
        "    ax.set_axis_off()\n",
        "\n",
        "# Ajustar el diseño para que no haya superposición\n",
        "plt.tight_layout()\n",
        "# Mostrar la figura con las subgráficas\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJmQOlUt0ii7"
      },
      "source": [
        "#<font color=\"red\"> 6.22 Un poco más de SOBEL\n",
        "\n",
        "El desenfoque es solo un uso de las convoluciones en el procesamiento de imágenes. Al utilizar ventanas más exóticas, podemos extraer diferentes tipos de información. El filtro Sobel intenta aproximar los gradientes de la imagen en una dirección utilizando funciones de ventana de la forma\n",
        "\n",
        "    [[-1,0,1],\n",
        "     [-2,0,2],\n",
        "     [-1,0,1]]\n",
        "\n",
        "Al encontrar el gradiente en ambas direcciones, X e Y, y luego calcular la magnitud de estos valores, obtenemos un mapa de los gradientes en una imagen para cada color."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJWSVY7L0ii7"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "n=100\n",
        "sobel_x = np.c_[\n",
        "    [-1,0,1],\n",
        "    [-2,0,2],\n",
        "    [-1,0,1]\n",
        "]\n",
        "\n",
        "sobel_y = np.c_[\n",
        "    [1,2,1],\n",
        "    [0,0,0],\n",
        "    [-1,-2,-1]\n",
        "]\n",
        "\n",
        "ims = []\n",
        "for d in range(3):\n",
        "    sx = convolve2d(im_small[:,:,d], sobel_x, mode=\"same\", boundary=\"symm\")\n",
        "    sy = convolve2d(im_small[:,:,d], sobel_y, mode=\"same\", boundary=\"symm\")\n",
        "    ims.append(np.sqrt(sx*sx + sy*sy))\n",
        "\n",
        "im_conv = np.stack(ims, axis=2).astype(\"uint8\")\n",
        "\n",
        "plti(im_conv,8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGUbnU7c0ii7"
      },
      "source": [
        "Los resultados son bastante impresionantes. Al combinar operaciones de filtrado y de detección de gradientes, podemos generar patrones extraños que se asemejan a la imagen original, pero están distorsionados de maneras interesantes. Lo mejor que he encontrado hasta ahora es la combinación de un filtro de mediana de ventana grande con un filtro Sobel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nyLMzYo0ii8"
      },
      "outputs": [],
      "source": [
        "im_smoothed = median_filter_all_colours(im_small, 71)\n",
        "\n",
        "sobel_x = np.c_[\n",
        "    [-1,0,1],\n",
        "    [-2,0,2],\n",
        "    [-1,0,1]\n",
        "]\n",
        "\n",
        "sobel_y = np.c_[\n",
        "    [1,2,1],\n",
        "    [0,0,0],\n",
        "    [-1,-2,-1]\n",
        "]\n",
        "\n",
        "ims = []\n",
        "for d in range(3):\n",
        "    sx = convolve2d(im_smoothed[:,:,d], sobel_x, mode=\"same\", boundary=\"symm\")\n",
        "    sy = convolve2d(im_smoothed[:,:,d], sobel_y, mode=\"same\", boundary=\"symm\")\n",
        "    ims.append(np.sqrt(sx*sx + sy*sy))\n",
        "\n",
        "im_conv = np.stack(ims, axis=2).astype(\"uint8\")\n",
        "\n",
        "plti(im_conv,8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exZCUwnU0ii9"
      },
      "source": [
        "Hasta ahora hemos visto cómo aplicar las mismas operaciones a todos los canales de color a la vez. Si desenfocamos solo un canal de color a la vez, obtenemos los siguientes efectos inquietantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INNICLng0ii9"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(15,5))\n",
        "\n",
        "ax= axs[0]\n",
        "ax.imshow(im_small)\n",
        "ax.set_title(\"Original\", fontsize=20)\n",
        "ax.set_axis_off()\n",
        "\n",
        "w=75\n",
        "window = np.ones((w,w))\n",
        "window /= np.sum(window)\n",
        "\n",
        "ax= axs[1]\n",
        "ims = []\n",
        "for d in range(3):\n",
        "    if d == 0:\n",
        "        im_conv_d = convolve2d(im_small[:,:,d],window, mode=\"same\", boundary=\"symm\")\n",
        "    else:\n",
        "        im_conv_d = im_small[:,:,d]\n",
        "    ims.append(im_conv_d)\n",
        "ax.imshow(np.stack(ims, axis=2).astype(\"uint8\"))\n",
        "ax.set_title(\"Red Blur\", fontsize=20)\n",
        "ax.set_axis_off()\n",
        "\n",
        "ax= axs[2]\n",
        "ims = []\n",
        "for d in range(3):\n",
        "    if d == 1:\n",
        "        im_conv_d = convolve2d(im_small[:,:,d], window, mode=\"same\", boundary=\"symm\")\n",
        "    else:\n",
        "        im_conv_d = im_small[:,:,d]\n",
        "    ims.append(im_conv_d)\n",
        "ax.imshow(np.stack(ims, axis=2).astype(\"uint8\"))\n",
        "ax.set_title(\"Blue Blur\", fontsize=20)\n",
        "ax.set_axis_off()\n",
        "\n",
        "ax= axs[3]\n",
        "ims = []\n",
        "for d in range(3):\n",
        "    if d == 2:\n",
        "        im_conv_d = convolve2d(im_small[:,:,d], window, mode=\"same\", boundary=\"symm\")\n",
        "    else:\n",
        "        im_conv_d = im_small[:,:,d]\n",
        "    ims.append(im_conv_d)\n",
        "ax.imshow(np.stack(ims, axis=2).astype(\"uint8\"))\n",
        "ax.set_title(\"Green Blur\", fontsize=20)\n",
        "ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFV3sTCG0ii9"
      },
      "source": [
        "# <font color=\"red\">6.23 Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "7ana6YQg0ii9"
      },
      "source": [
        "Otra área importante del procesamiento de imágenes es segmentar la imagen en diferentes regiones, como el primer plano y el fondo. Hay varias formas de hacerlo, y aquí solo analizaré algunas.\n",
        "\n",
        "La más sencilla es convertir la imagen a escala de grises y encontrar un umbral. Los píxeles con un valor por encima del umbral se consideran pertenecientes a una región, y los que están por debajo, a otra región. Podemos explorar cómo elegir diferentes umbrales segmenta nuestra imagen en escala de grises a continuación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMEXXR5XYred"
      },
      "source": [
        "##<font color=\"red\"> 6.24 Aplicación de Umbral (Thresholding) en una Imagen en Escala de Grises\n",
        "\n",
        "Este código aplica un umbral (threshold) a una imagen en escala de grises utilizando diferentes valores de umbral.\n",
        "\n",
        "*El umbral es un valor que se utiliza para dividir la imagen en dos regiones:*\n",
        "\n",
        " * Los píxeles con valores por encima del umbral se convierten en 255 (blancos)\n",
        " * Los píxeles con valores por debajo se convierten en 0 (negros).\n",
        "\n",
        "Esto es útil para tareas de segmentación de imágenes, donde se necesita separar áreas de interés. El código crea subgráficas que muestran la imagen segmentada con diferentes valores de umbral.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLmy1fdNZXvd"
      },
      "outputs": [],
      "source": [
        "def to_grayscale(im):\n",
        "    \"\"\"\n",
        "    Convierte una imagen RGB a escala de grises utilizando la fórmula ponderada estándar.\n",
        "\n",
        "    Argumentos:\n",
        "    im -- Imagen en formato RGB (alto, ancho, 3)\n",
        "\n",
        "    Retorna:\n",
        "    La imagen en escala de grises (alto, ancho)\n",
        "    \"\"\"\n",
        "    # Usar la fórmula de conversión a escala de grises\n",
        "    return 0.2989 * im[:,:,0] + 0.5870 * im[:,:,1] + 0.1140 * im[:,:,2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "THy8Vh8M6n_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWX0VygZ0ii-"
      },
      "outputs": [],
      "source": [
        "def simple_threshold(im, threshold=128):\n",
        "    \"\"\"\n",
        "    Aplica un umbral simple a la imagen `im`.\n",
        "    Si un píxel es mayor que el umbral, se asigna el valor 255 (blanco),\n",
        "    de lo contrario, se asigna el valor 0 (negro).\n",
        "    \"\"\"\n",
        "    # Se compara cada valor de píxel con el umbral.\n",
        "    # Si es mayor, se convierte en 255, de lo contrario se convierte en 0.\n",
        "    return ((im > threshold) * 255).astype(\"uint8\")  # Convertir a tipo uint8 para imagen binaria\n",
        "\n",
        "# Diferentes valores de umbral que vamos a probar\n",
        "thresholds = [100, 120, 128, 138, 150]\n",
        "\n",
        "# Crear una figura con subgráficas para mostrar los resultados\n",
        "fig, axs = plt.subplots(nrows=1, ncols=len(thresholds), figsize=(20, 5));\n",
        "\n",
        "# Convertir la imagen original a escala de grises (asegúrate de que la función to_grayscale esté definida)\n",
        "gray_im = to_grayscale(im)  # Aquí `im` es la imagen original, y `to_grayscale` debe convertirla a gris.\n",
        "\n",
        "# Aplicar el umbral para cada valor en la lista `thresholds`\n",
        "for t, ax in zip(thresholds, axs):\n",
        "    # Aplicar el umbral en la imagen en escala de grises\n",
        "    ax.imshow(simple_threshold(gray_im, t), cmap='Greys')  # Mostrar la imagen con el umbral aplicado\n",
        "    ax.set_title(\"Threshold: {}\".format(t), fontsize=20)  # Título con el valor del umbral\n",
        "    ax.set_axis_off()  # Desactivar los ejes para una mejor visualización\n",
        "\n",
        "# Ajustar el diseño de la figura\n",
        "plt.tight_layout()\n",
        "# Mostrar la figura\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPpURG9Z0ii-"
      },
      "source": [
        "Cómo elegimos un umbral específico dependerá de la aplicación. Sin embargo, podemos argumentar que esperaríamos que los valores de los píxeles del fondo sean similares entre sí, al igual que los del primer plano. Una forma de cuantificar esto es buscar el umbral que minimice la varianza entre los píxeles del primer plano y del fondo. Una manera de calcular esto es a través del algoritmo de umbralización de Otsu, que se implementa a continuación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0dyqVjLZqIW"
      },
      "source": [
        "## <font color=\"red\"> 6.25 Algoritmo de Umbralización de Otsu para Segmentación de Imágenes\n",
        "\n",
        "El algoritmo de umbralización de Otsu es una técnica automática de segmentación de imágenes en la que se busca un umbral que minimice la varianza intra-clase (la dispersión de los píxeles dentro de cada clase). Este método es muy útil cuando se quiere dividir una imagen en dos clases, típicamente fondo y primer plano, de manera automática sin necesidad de intervención humana.\n",
        "\n",
        "\n",
        "La técnica calcula el umbral que maximiza la diferencia entre las clases de píxeles, es decir, separa mejor las zonas claras y oscuras de la imagen. Esto se logra a través del análisis de la histograma de la imagen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txJNhqUd0ii-",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def otsu_threshold(im):\n",
        "    \"\"\"\n",
        "    Aplica el algoritmo de umbralización de Otsu a una imagen en escala de grises.\n",
        "\n",
        "    Argumentos:\n",
        "    im -- Imagen en escala de grises (2D)\n",
        "\n",
        "    Retorna:\n",
        "    Umbral calculado por el método de Otsu.\n",
        "    \"\"\"\n",
        "    # Contar el número de píxeles para cada valor de intensidad (0 a 255)\n",
        "    pixel_counts = [np.sum(im == i) for i in range(256)]\n",
        "\n",
        "    s_max = (0,-10)  # Inicializar el valor máximo de la varianza inter-clase\n",
        "    ss = []  # Lista para almacenar las varianzas calculadas para cada umbral\n",
        "\n",
        "    # Iterar sobre todos los posibles valores de umbral\n",
        "    for threshold in range(256):\n",
        "\n",
        "        # Calcular las probabilidades de las clases 0 y 1 para un umbral dado\n",
        "        w_0 = sum(pixel_counts[:threshold])  # Peso de la clase 0 (por debajo del umbral)\n",
        "        w_1 = sum(pixel_counts[threshold:])  # Peso de la clase 1 (por encima del umbral)\n",
        "\n",
        "        # Calcular la media de la clase 0 y clase 1\n",
        "        mu_0 = sum([i * pixel_counts[i] for i in range(0,threshold)]) / w_0 if w_0 > 0 else 0\n",
        "        mu_1 = sum([i * pixel_counts[i] for i in range(threshold, 256)]) / w_1 if w_1 > 0 else 0\n",
        "\n",
        "        # Calcular la varianza inter-clase para el umbral dado\n",
        "        s = w_0 * w_1 * (mu_0 - mu_1) ** 2\n",
        "        ss.append(s)\n",
        "\n",
        "        # Actualizar el valor máximo de la varianza inter-clase\n",
        "        if s > s_max[1]:\n",
        "            s_max = (threshold, s)\n",
        "\n",
        "    return s_max[0]  # Devolver el umbral que maximiza la varianza\n",
        "\n",
        "# Ejemplo de uso con una imagen en escala de grises\n",
        "t = otsu_threshold(gray_im)  # Aplicar el algoritmo de Otsu para obtener el umbral\n",
        "plt.imshow(simple_threshold(gray_im, t), cmap='Greys')  # Aplicar el umbral obtenido a la imagen y mostrarla\n",
        "plt.title(f\"Umbral Otsu: {t}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O4ZPseN0ii-"
      },
      "source": [
        "No es ideal. Sin embargo, podemos pensar que al convertir nuestra imagen a escala de grises estamos perdiendo información. Podemos aplicar el mismo proceso a cada canal de color por separado para obtener resultados más detallados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fmSWAj0aetw"
      },
      "source": [
        "##<font color=\"blue\">6.25.1 Aplicación del Umbral de Otsu en los Canales de Color de una Imagen\n",
        "\n",
        "Este código aplica el algoritmo de umbralización de Otsu en cada uno de los tres canales de color (Rojo, Verde, Azul) de una imagen. Para cada canal, calcula el umbral óptimo utilizando el método de Otsu y aplica dicho umbral para binarizar la imagen. Los resultados se muestran en una figura con tres subgráficos, uno para cada canal.\n",
        "\n",
        "El proceso se realiza en los siguientes pasos:\n",
        "\n",
        "1. Se toma cada uno de los tres canales de la imagen.\n",
        "2. Se calcula el umbral de Otsu para cada canal.\n",
        "3. Se aplica el umbral para binarizar la imagen del canal.\n",
        "4. Se muestra la imagen binarizada de cada canal en un subgráfico.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5ww6tbw0ii-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Asumiendo que la función otsu_threshold y simple_threshold ya están definidas\n",
        "\n",
        "# Crear la figura con 3 subgráficos para los 3 canales (RGB)\n",
        "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\n",
        "\n",
        "# Lista para almacenar las imágenes binarizadas de los tres canales\n",
        "c_ims = []\n",
        "\n",
        "# Iterar sobre los tres canales (R, G, B)\n",
        "for c, ax in zip(range(3), axs):\n",
        "    tmp_im = im[:,:,c]  # Extraer el canal c de la imagen\n",
        "    t = otsu_threshold(tmp_im)  # Calcular el umbral de Otsu para el canal\n",
        "    tmp_im = simple_threshold(tmp_im, t)  # Aplicar el umbral de Otsu para binarizar\n",
        "    ax.imshow(tmp_im, cmap='Greys')  # Mostrar la imagen binarizada en el subgráfico\n",
        "    c_ims.append(tmp_im)  # Añadir la imagen binarizada a la lista\n",
        "    ax.set_axis_off()  # Ocultar los ejes\n",
        "\n",
        "plt.tight_layout()  # Ajustar el diseño para que no se solapen los subgráficos\n",
        "plt.show()  # Mostrar la figura con las imágenes binarizadas de los canales\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyiB8tBN0ii_"
      },
      "source": [
        "Una forma natural de combinar cada canal en una sola imagen es tomar la intersección de cada canal de color umbralizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiQcrwsQ0ii_"
      },
      "outputs": [],
      "source": [
        "# Combinar las tres imágenes binarizadas en una sola imagen y mostrarla\n",
        "combined_image = np.stack(c_ims, axis=-1)  # Combina las imágenes en una sola (RGB)\n",
        "plt.imshow(np.mean(combined_image, axis=-1), cmap='Greys')  # Promediar y mostrar la imagen combinada\n",
        "plt.title(\"Imagen combinada de los 3 canales con umbral de Otsu\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cilqOj2F0ijF"
      },
      "source": [
        "Lo cual funciona mucho mejor que simplemente observar la imagen en escala de grises.\n",
        "\n",
        "Sin embargo, podemos ser más directos en nuestro enfoque. En la umbralización de Otsu, encontramos el umbral que minimiza la varianza de los píxeles entre segmentos. Si, en lugar de buscar un umbral, buscamos grupos en el espacio de color, terminamos con la técnica de K-means. Al aplicar esto directamente a la imagen en color, obtenemos resultados que son más efectivos para la segmentación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzVTmoAV061g"
      },
      "source": [
        "##<font color=\"red\"> 6.26 Segmentación de imagen utilizando KMeans\n",
        "\n",
        "Este código realiza una segmentación de la imagen utilizando el algoritmo de agrupamiento KMeans.\n",
        "\n",
        "La segmentación divide la imagen en un número específico de clústeres, en este caso, 3. A través de KMeans, los píxeles de la imagen se agrupan según sus valores de color, y luego se asignan colores promedio (centros de los clústeres) a los píxeles dentro de cada clúster.\n",
        "\n",
        "El resultado es una imagen segmentada en diferentes regiones, cada una representada por un color promedio correspondiente a su clúster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZfFMlTz0ijF"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Suponiendo que la imagen `im_small` ya está cargada y preprocesada.\n",
        "\n",
        "# Obtener las dimensiones de la imagen\n",
        "h, w = im_small.shape[:2]\n",
        "\n",
        "# Reformar la imagen a una lista de píxeles\n",
        "im_small_long = im_small.reshape((h * w, 3))\n",
        "\n",
        "# Crear el modelo KMeans con 3 clústeres\n",
        "km = KMeans(n_clusters=3)\n",
        "\n",
        "# Ajustar el modelo a los datos de los píxeles\n",
        "km.fit(im_small_long)\n",
        "\n",
        "# Obtener los centros de los clústeres (colores promedio de cada clúster)\n",
        "cc = km.cluster_centers_.astype(np.uint8)\n",
        "\n",
        "# Asignar a cada píxel el centro del clúster correspondiente\n",
        "out = np.asarray([cc[i] for i in km.labels_]).reshape((h, w, 3))\n",
        "\n",
        "# Mostrar la imagen segmentada\n",
        "plt.imshow(out)\n",
        "plt.title(\"Segmentación con KMeans (3 Clústeres)\")\n",
        "plt.axis('off')  # Eliminar los ejes\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMGCA3yh0ijF"
      },
      "source": [
        "Lo cual no está nada mal. Al asignar colores aleatorios a cada uno de los segmentos, podemos crear arte de una manera interesante y creativa.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4wcD43y12My"
      },
      "source": [
        "#<font color=\"red\">6.27 Segmentación con Colores Aleatorios usando KMeans\n",
        "\n",
        "Este código muestra cómo segmentar una imagen en base a los clústeres generados por el algoritmo KMeans y asignar colores aleatorios a los diferentes clústeres. La imagen se convierte a escala de grises, luego se aplica KMeans para clasificar los píxeles en clústeres. Posteriormente, en cada ejecución, se asignan colores aleatorios a los clústeres y se visualizan las imágenes segmentadas con esos colores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2bU3KpP0ijF"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Suponiendo que la imagen `im` ya está cargada y preprocesada.\n",
        "\n",
        "# Función para convertir a escala de grises\n",
        "def to_grayscale(im):\n",
        "    return np.dot(im[...,:3], [0.2989, 0.5870, 0.1140])\n",
        "\n",
        "# Reducir el tamaño de la imagen para optimización\n",
        "im_small = im  # Asume que la imagen ya está cargada\n",
        "\n",
        "# Obtener las dimensiones de la imagen\n",
        "h, w = im_small.shape[:2]\n",
        "\n",
        "# Reformar la imagen a una lista de píxeles\n",
        "im_small_long = im_small.reshape((h * w, 3))\n",
        "\n",
        "# Crear el modelo KMeans con 3 clústeres\n",
        "km = KMeans(n_clusters=3)\n",
        "\n",
        "# Ajustar el modelo a los datos de los píxeles\n",
        "km.fit(im_small_long)\n",
        "\n",
        "# Crear una secuencia de índices para recorrer el número de imágenes generadas\n",
        "rng = range(4)\n",
        "\n",
        "# Preparar el gráfico para mostrar varias imágenes\n",
        "fig, axs = plt.subplots(nrows=1, ncols=len(rng), figsize=(15,5))\n",
        "\n",
        "# Convertir la imagen original a escala de grises\n",
        "gray_im = to_grayscale(im)\n",
        "\n",
        "# Generar imágenes segmentadas con colores aleatorios\n",
        "for t, ax in zip(rng, axs):\n",
        "    # Generar colores aleatorios para los clústeres\n",
        "    rnd_cc = np.random.randint(0, 256, size=(3, 3))\n",
        "\n",
        "    # Crear la imagen segmentada con los colores aleatorios\n",
        "    out = np.asarray([rnd_cc[i] for i in km.labels_]).reshape((h, w, 3))\n",
        "\n",
        "    # Mostrar la imagen segmentada\n",
        "    ax.imshow(out)\n",
        "    ax.set_axis_off()\n",
        "\n",
        "# Ajustar el diseño y mostrar la imagen\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjLRWaVe0ijG"
      },
      "source": [
        "# <font color=\"red\">6.28 Vectorization\n",
        "Hasta ahora hemos tratado la imagen como un mapa de bits. Como último paso, voy a extraer el segmento prinicipal de la imagen y convertirlo en una imagen vectorizada, dejando el fondo en negro.\n",
        "\n",
        "##<font color=\"blue\">6.28.1 Segmentación de Imagen con KMeans y Resaltado de un Clúster Específico\n",
        "\n",
        "Este código utiliza el algoritmo KMeans para segmentar una imagen en clústeres y luego resalta un clúster específico (en este caso, el clúster con índice 2).\n",
        "\n",
        "Los píxeles que pertenecen al clúster seleccionado se mantienen con el color original del centroide, mientras que los otros píxeles se establecen en negro. Esto permite destacar visualmente un clúster particular, como si fuera una máscara o un resaltado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M266rCZ30ijG"
      },
      "outputs": [],
      "source": [
        "cluster = np.asarray([cc[i] if i == 2 else [0,0,0]\n",
        "                  for i in km.labels_]).reshape((h,w,3))\n",
        "\n",
        "plti(cluster,8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELep3t_t0ijG"
      },
      "source": [
        "#<font color=\"red\"> 6.29 Encontrar y Aproximar Contornos de un Clúster con KMeans\n",
        "\n",
        "Este código utiliza la segmentación previa de la imagen realizada por KMeans para identificar y visualizar los contornos de un clúster específico (en este caso, el clúster con índice 1). Luego, se aproxima el contorno utilizando el algoritmo de aproximación de polígonos. Finalmente, los contornos aproximados son graficados sobre la imagen original. Este enfoque es útil para resaltar las formas o áreas relevantes dentro de un clúster segmentado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzxubJ_m0ijG"
      },
      "outputs": [],
      "source": [
        "from skimage import measure\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Supongamos que la imagen `im` y el modelo `km` ya están cargados y preprocesados.\n",
        "\n",
        "# Reducir el tamaño de la imagen para optimización\n",
        "im_small = im  # Asume que la imagen ya está cargada\n",
        "\n",
        "# Obtener las dimensiones de la imagen\n",
        "h, w = im_small.shape[:2]\n",
        "\n",
        "# Reformar la imagen a una lista de píxeles\n",
        "im_small_long = im_small.reshape((h * w, 3))\n",
        "\n",
        "# Crear el modelo KMeans con 3 clústeres\n",
        "km = KMeans(n_clusters=3)\n",
        "\n",
        "# Ajustar el modelo a los datos de los píxeles\n",
        "km.fit(im_small_long)\n",
        "\n",
        "# Obtener los centroides de los clústeres\n",
        "cc = km.cluster_centers_.astype(np.uint8)\n",
        "\n",
        "# Crear una segmentación binaria de los píxeles pertenecientes al clúster 1\n",
        "seg = np.asarray([(1 if i == 1 else 0)  # Píxeles del clúster 1 serán 1, el resto será 0\n",
        "                  for i in km.labels_]).reshape((h, w))\n",
        "\n",
        "# Encontrar los contornos en la segmentación binaria\n",
        "contours = measure.find_contours(seg, 0.5, fully_connected=\"high\")\n",
        "\n",
        "# Aproximar los contornos encontrados\n",
        "simplified_contours = [measure.approximate_polygon(c, tolerance=5) for c in contours]\n",
        "\n",
        "# Mostrar la imagen con los contornos aproximados\n",
        "plt.figure(figsize=(5, 10))\n",
        "\n",
        "# Graficar los contornos aproximados\n",
        "for n, contour in enumerate(simplified_contours):\n",
        "    plt.plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
        "\n",
        "# Ajustar límites y aspecto de la gráfica\n",
        "plt.ylim(h, 0)\n",
        "plt.axes().set_aspect('equal')\n",
        "plt.title(\"Contornos Aproximados del Clúster 1\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.4.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}